#+title: 
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+BEGIN_outline-text-1
#+BEGIN_CENTER
#+BEGIN_XLARGE
Classical Planning

in Deep Latent Space
#+END_XLARGE

東京大学大学院 博士3年 -- *就活中!*

総合文化研究科　(渋谷駒場キャンパス)

学振DC2

浅井 政太郎
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* もくじ

+ 深層学習 -- は解説の必要はありませんね?
+ 記号的汎用AIプランニング
+ 深層学習 + AIプランニング

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 199X年
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 AIは予算削減の冬に覆われた
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 あらゆる記号的AI研究者は

 絶滅したかに思えた
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_XLARGE
 #+BEGIN_CENTER
 しかし 記号は

 死に絶えてはいなかった!
 #+END_CENTER
 #+END_XLARGE

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 Classical Planning

 in Deep Latent Space:

 記号をとりもどせ!
 #+END_XLARGE
 #+END_CENTER

* イントロ -- 専攻分野 -- AIプランニング

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

  #+BEGIN_RESUME
  And let me introduce these robots.
  The guy in the left is Astro boy.
  #+END_RESUME

*** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/2]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 As you know, he is a famous manga superhero invented by Tezuka Osamu in 50s,
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/1]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 and he can think, hear, speak, act. he also has emotions.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/2]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
  In contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  His name is T-52 Enryu, developped by a Japanese company Temzak.
  He is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  Well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/3]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 But does he have feelings or can he think? Can he even move around by his own?
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/final]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 No. It requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. It is more like a
 super-sophisticated shovel car.
 #+END_RESUME

** 実際の大規模災害では非実用的 --- 操縦士が足りない!

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+END_SPAN2
 #+BEGIN_SPAN10
 [[jpg:static/tsunami]]
 #+END_SPAN10
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_LARGER
 #+BEGIN_ALIGNRIGHT
 + そのままでは役に立たない!
 #+END_ALIGNRIGHT
 #+END_LARGER

 #+BEGIN_RESUME
 Now the problem is : It's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in Japan.
 The key resource is human ---
 These special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+END_RESUME

*** 操縦士を増やせない -- Human Resource and Training

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN4
  [[png:rescue/1]]
 #+END_SPAN4
 #+BEGIN_SPAN8

   + ✘ /時間/ がかかる :: 訓練に ＞100時間, *必要な時だけ増やす* のは不可能
   + ✘ /￥￥￥￥/ がかかる :: 訓練官、訓練場所、訓練用具
   + ✘ 技術は /維持が重要/ :: 定期的な再訓練、長期的コスト、さらなるマニー
   + ✘ 平時は /無駄/ な技術 :: 普段は意味がない -- 無駄なマニー!
 #+END_SPAN8
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 In a natural disaster, we need as many experienced operators as possible.
 However, it is virtually impossible due to several reasons. 

 First, training takes time.
 It is impossible to quickly increase the number of operators as needed, at the time of disaster.

 Second, the money matters.
 Training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 Third, Skills need to be updated and maintained.
 You know, how about preparing the large number of operators in advance?
 No, the society cannot torelate the cost of keep training them.
 Operators may lose the skills and skills may become outdated.

 Finally, in a normal situation, those skills are useless.
 It forces the society to waste a great amount of extra money.
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/1]]

 #+BEGIN_RESUME
 研究テーマのプランニングは、ロボットに、人間の助けを借りず、いかに自律して行動させるかを扱います。
 これをモデル化したプランニング問題は、具体的な行動の列を求める 組合せ最適化問題です。

 プランニング問題のタスクは、
 センサーから初期状態とゴールを受け取って、被災者を助ける正しい手順を出力することです。

 たとえば、この図では男性が瓦礫に埋まって助けを求めています。
 プランニング機能のあるロボットは、コレに対して「男性を助けよ」という大まかな指示を受けます。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/2]]

 #+BEGIN_RESUME
 指示の内容には、図のように初期状態とゴール、許可された行動のリストが入っています。
 ロボットは、自動プランニングにより、人間の代わりに適切な行動を組み立てて、ゴールを自動で達成します。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/final]]

 #+BEGIN_RESUME
 プランニングは汎用な枠組みなので、災害救助以外にも様々な問題に適用することができます。
 現実の応用例では「宇宙探査機運行問題」や「企業ネットワーク脆弱性問題」も表現できます。

 このように、プランニングは、難しい問題を汎用性を失わずに解くことを目指します。
 #+END_RESUME

** AIプランニングの */Killer App/*

+ 人では不可能な作業の代替 :: 危険な環境, 宇宙空間・深海, 24時間対応
+ コストのかかる人間の代替・自動化 :: 機械工作, 人工衛星運営(専門家の時給が高い!)
+ 最適性/理論保証の求められるミッションクリティカルシステム :: 人工衛星運営(最も少ない燃料で運用)

** AIと自動プランニング の位置づけ -- /理論/ と /実応用/ の中間    :noexport:

 緑は /理論/ 、オレンジは /実応用/ 、 AI はその橋渡し (どれともかぶらない部分もある)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning-related-field]]

* プランニング問題 (決定的,完全情報) -- Blocksworld

#+HTML: <embed src="img/plan.svg" type="image/svg+xml"  />

** アクション = 条件付き状態遷移

#+BEGIN_CENTER
#+BEGIN_XLARGE
アクション (move ?X ?Y)
#+END_XLARGE
#+END_CENTER

#+BEGIN_CENTER
*?X*, *?Y* : 変数。 値 *BLOCK-A*, *BLOCK-B* などを適用して使う

*前提条件* と *効果* で構成される
#+END_CENTER
#+BEGIN_QUOTE
*前提条件* が満たされた時…

命題 (clear *?X*) : 積み木 *?X* の上に何も置かれていない

命題 (clear *?Y*) : 積み木 *?Y* の上に何も置かれていない

*効果* を適用

⇒ 命題 (on *?X* *?Y*) を追加 : *?X* が *?Y* の上に移動

⇒ 命題 (clear *?Y*) を削除 : *?Y* は clear ではなくなる
#+END_QUOTE

** *PDDL* : Planning Domain Description Language

International Planning Competition で使われている入力形式

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN8
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN8
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_NOTE
宇宙探査機 NASA DS1 上の Remote Agent 自動航行システム でも
 "DDL" という名で 似たような記述言語があったようだ
#+END_NOTE

** プランニング = グラフ探索

*ノード* : 状態 = 命題の集合 ⇒ =(on A B)=, =(clear A)= など

*辺*     : アクション ⇒ =(move A B)= 等

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ヒューリスティック探索 A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  
** Q. いま */はやり/* のDeep Learningとの違いは?

 A. レイヤが違う

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *機械学習・Neural Networks* 
 
 for *認識・反射*
 + 入力 は *Subsymbolic* (連続値)
   
   画像、音声、非構造化テキスト: 
 + *直感/脊髄反射的知能*:
   
   　 *_直後_ の行動の決定*
   #+BEGIN_SMALLER
   *パブロフの犬* : 餌→よだれ

   *自動運転* : 赤信号,人 → 止まる.

   *翻訳* : 文章 → 文章

   *囲碁局面の評価関数* : 局面 → 勝率
   #+END_SMALLER
   ☺ 効率よく 1-to-1 mapping
   
   ☹ 単純作業
 #+END_SPAN6
 #+BEGIN_SPAN6
 *推論・探索*

 for *プランニング・ゲーム・定理証明*
 + 入出力は *Symbolic*
   
   論理 オブジェクト ルール
 + *論理・推論による知能:*

   　 *_未来に渡る_ 戦略の決定*
   
   　 (戦略 = 行動の *列や木*)
   #+BEGIN_SMALLER
   *レスキューロボ* : ゴール = 被災者生存

   *証明器* : ゴール = QED

   *コンパイラ* : 命令列の生成
   
   *囲碁,将棋* : ゴール = 勝利
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ 時間的依存関係を含む論理の組み合わせ
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

+ AlphaGo = Subsymbolic (DLNNによる評価関数) + Symbolic (MCTSによる探索)

** 既存の有名システム

+ AlphaGo = Subsymbolic (NNによる評価関数の学習) + Symbolic (UCT-MCTSによる探索)
  + ただし *ドメイン依存* -- 囲碁に特化, "マス目"や"石"といった概念をハードコード
  + *膨大な棋譜が必要* --- 運用データしかない環境(e.g.火星)には適用不能
  + */人って棋譜がないと行動できませんか??/*
+ DQN = DLNN (*Subsymbolic*) + Reinforcement Learning (*Subsymbolic*)
  + 様々な Atari Game につかえる汎用的なフレームワーク (Invader, Packman…) だが
  + 殆どのゲームは *脊髄反射的な操作で長く生き残ることが出来る*
  + RLのActing: 学習したpolicyに従ってgreedyに行動
  + *Atariゲームに複雑な論理思考能力は必要ない* から RL で成功
  + 実際、 *Sokoban など論理思考が求められるAtariゲームでは性能が良くない*

* Yann LeCun 御大

[[png:lecun]]

#+BEGIN_ALIGNRIGHT
それと去年の松尾先生
#+END_ALIGNRIGHT

* IJCAI投稿内容

#+BEGIN_XLARGE
#+BEGIN_CENTER
Classical Planning in

 Deep Latent Space:

From Unlabelled Images to PDDL (and back)
#+END_CENTER
#+END_XLARGE

** 高度に知的な機械を作るには → DeepLearning + 論理と推論

#+BEGIN_CENTER
#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
+ ディープラーニングのみ
  
  ↓
  
  虫程度の知能を持った
  
  *反射的な機械*
#+END_SPAN5
#+BEGIN_SPAN2
　

vs

　
#+END_SPAN2
#+BEGIN_SPAN5
+ */DL + 論理、推論、思考/*
  
  ↓
  
  */目標を達成するために/*
  
  */論理で戦略を練る機械/*

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID
#+END_CENTER

[[png:planning-deeplearning]]
** ゴール

#+BEGIN_XLARGE
#+BEGIN_CENTER
State of the Art

Deep Learning 

＋

State of the Art

Classical Planning
#+END_CENTER
#+END_XLARGE

** 3x3 スライディング タイル パズル (8-Puzzle)

空きパネルとそれ以外を移動させることで絵を完成させるパズル

[[sjpg:puzzle]]

#+BEGIN_ALIGNRIGHT
*古典的なAI問題として知られている*

可能な曲面の数は 362880 個

4x4の15-パズル、5x5の24-パズルはさらに難しい
#+END_ALIGNRIGHT

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で 8-puzzle を解くAIシステムを作る

*棋譜なし* : 棋譜から学習した勘(評価関数)で解くAlphaGoと異なる

*事前知識なし* : 「パネル」「9マスある」「パネルが動く」などの事前知識(ラベル、シンボル)は与えられない

[[sjpg:puzzle]]

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で */任意の問題/* を解くAIシステムを作る

*8-puzzle だけでなく 任意の問題を解く*

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
ハノイの塔

[[sjpg:hanoi]]
#+END_SPAN6
#+BEGIN_SPAN6
Lights-Out

[[sjpg:lightsout]]
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

* 

#+BEGIN_XLARGE
#+BEGIN_CENTER
システム概要
#+END_CENTER
#+END_XLARGE

** 入力1: Training Inputs -- Image Pairs

実行可能なアクションの例を示す画像ペア

[[png:overview/1]]

** 入力1: Training Inputs -- Image Pairs

[[png:overview/2]]

** 入力2: Planning Inputs -- Initial Image & Goal Image

探すべきプランの *始点と終点* にある2つの状態 を示す画像

[[png:overview/input2]]

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で */任意の問題/* を解くAIシステムを作る

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で */任意の問題/* を解くAIシステムを作る

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />

** 実行例 (MNIST 8-puzzle)

[[png:results/mnist-plan]]

** 実際の問題の例 (Mandrill 8-puzzle)

MNIST 8-puzzle は 「物体」のようなものが明確に分離されている

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/mandrill-intro]]

** 実行例 (Mandrill 8-puzzle)

[[png:results/mandrill-plan]]

** 実行例 (Tower of Hanoi)

全く意味の異なる入力でも解けることを示す

[[png:results/hanoi3]]

[[png:results/hanoi4]]

** 実行例 (Lights Out)

8-puzzle も hanoi も 「物体」のようなものが「消えない」という性質がある。

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out]]

** 実行例 (Skewed Lights Out)

8-puzzle, hanoi, LightsOut は 「物体」のようなものが格子状に並んでいる

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out-skewed]]

** ノイズのある入力にも対応

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

# (ノイズのある入力 $r$ と、それにSAEを適用した $Decode(Encode(r))$ の比較)

* どうやって作ったのか？ 予想された困難

基本アイディア: DLNN + Classical Planner

+ 1. ラベル無し画像データからなんとかして知識を取り出したい

  + *どんな知識をどうやって?* ← *自明でない*

+ 2. 取り出せたとする。NNで発見される知識は Subsymbolic: 実数値

  + プランナが必要とするのは Symbolic な入力: 離散値・命題・真偽値

  + システム全体が Unsupervised, 画像入力だけでラベル無し 

  + Subsymbolic を Symbol をどう変換する? (*Symbol Grounding*) ← *自明でない*

+ 3. 仮に自動的に Symbol を 生成したとして

  + 自動的に作られた Symbol は人に理解できる形式ではおそらくない

  + *機械のSymbolをどうやって人の理解できる形式にするか？* ← *自明でない*

* Latent-space Planner: */LatPlan/*

*学習*, *Symbol Grounding*, *Symbolの解釈* を同時に解決する *アーキテクチャ*

 [[png:overview/planning]]

#+BEGIN_ALIGNRIGHT
本プレゼンテーションでは、 LatPlan と その *1実装* LatPlanα を紹介
#+END_ALIGNRIGHT

* Step 1: State Autoencoder

*Symbolic/Subsymbolic の壁を超える* ために・・・

 [[png:overview/planning2]]

** Step 1: State Autoencoder

 [[png:sae/state-ae]]

** AutoEncoder (おさらい)

#+BEGIN_CENTER
*教師なし学習*

入力空間 *S* を Latent Space *L* に *圧縮*

かつ *S* に *展開* して *元の画像に損失無く戻す。*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
→ *データ* $x$ をコンパクトな *Latent vector* $z$ に変換/逆変換するNNを学習

→ しかし、 */✘ Latent vector は 実数値 のよくわからん値/*
#+END_ALIGNRIGHT

** Deep Autoencoder                                                :noexport:

 いろいろな追加技術を使うことでDeepにできる → *より圧縮できる*

 Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

 [[png:static/deep-ae]]

** Gumbel-Softmax Reparametrization (Jang, Gu, ICLR2017)

 *中間層がカテゴリカル分布(離散値)なVAEを作る手法*

VAE: 中間層が特定の分布を持つAEのこと

#+BEGIN_CENTER
 #+BEGIN_HTML
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+END_HTML
#+END_CENTER

#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
鍵となるアイディア: *この離散表現は記号的ソルバで使用可能*
#+END_LARGER
#+END_ALIGNRIGHT

** Gumbel-Softmax: Gumbel-Max の微分可能な近似

Gumbel-Max: カテゴリごとの確率 ($x$) から one-hot vector ($z$) をサンプルする手法

+ 例: $x=[0.1, 0.1, 0.8] \rightarrow z = [0, 0, 1] \text{or} [1,0,0] \text{or} [0,1,0]$ (確率にそって)

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ 微分可能でない → BP法が使えない → max を 微分可能なsoftmax で近似

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ 温度 $\tau$ を0に近づけるとGumbelMaxに収束: $z$ もone-hotに収束

  \[
  \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  \]

#+BEGIN_NOTE
Maddison et. al., 2014
#+END_NOTE
** Gumbel-Softmax

[[png:sae/gumbel]]

$N\times M$ 行列を出力, $N$: 変数の数 $M$: カテゴリの数

#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
鍵となるアイディア: *この離散表現は記号的ソルバで使用可能*

特に *カテゴリ数2 → N個の命題(true/false)に直接マップ可能*
#+END_LARGER
#+END_ALIGNRIGHT

** Step 1: State Autoencoder

[[png:train-state-ae]]

SAEを学習させることにより以下の関数を得る:

+ $b = Encode(r)$ : *生データ $r$ を boolean vector に変換する関数*

+ $\tilde{r} = Decode(b)$ : *boolean vector $b$ を 生データ $\tilde{r}$ に変換する関数*

** LatPlan の実装 LatPlan α でのSAE

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

8-puzzle の訓練は、可能な全状態 (362880) 中 *12000 枚のみを用いて* 訓練する。 

→ 少ない画像を用いて学習可能。

* Step 2: Action Model Acquisition

bitvector から PDDL モデルを生成

 [[png:overview/planning3]]

** LatPlan の実装 LatPlan α での アクション集合の生成

個別アクション遷移をPDDLアクション表現にマップ

#+BEGIN_SRC lisp
0011 → 0101

↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; 遷移前の状態
 :effect       (and (not (b1-false)) (b1-true)    ; false命題を取り除き、true命題を追加
                    (not (b2-true))  (b2-false)))
#+END_SRC

ポイント: $i$ ビット目が 0/1 であるとき ($b_i$-true)/($b_i$-false) という命題になる

** LatPlan の実装 LatPlan α での アクション集合の生成

_全遷移の画像ペアを生成_

→ 訓練済みのSAEを用いてbitvectorに

→ bitvectorを用いてPDDL表現に

#+BEGIN_ALIGNRIGHT
… _全遷移の画像ペアを生成??__
#+END_ALIGNRIGHT

** LatPlan の実装 LatPlan α での アクション集合の生成

現時点の制限: *一般化を行えない*

遷移前の全ビットを指定 → 将来的には *より汎化されたルールが必要*

: 未汎化の遷移   0011 → 0101
: 汎化された遷移 *01* → *10*

→ Domain Acquisition というAI分野でよく研究されている 

* Step 3: PDDL モデルを解く

 [[png:overview/planning4]]

* Step 4: 記号的プラン(人には理解不能)を 人の理解できる画像に戻す

 [[png:overview/planning5]]

* 評価

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ 学習: 30分程度
+ 求解: 3秒程度

** State AutoEncoder                                               :noexport:

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像

[[spng:experiment/autoencoding_test]]

#+BEGIN_ALIGNRIGHT
きちんと学習できている
#+END_ALIGNRIGHT

** State AutoEncoder                                               :noexport:

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

$N=25$ の例

#+BEGIN_SRC lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+END_SRC

** Fast Downward Log Trace (Search Statistics)                     :noexport:

#+BEGIN_SRC
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+END_SRC

** わざわざプランニングソルバを使う理由は?

なぜ、ただの幅優先やDijkstra探索ではだめなの?

→ ドメイン非依存ソルバの高度な枝刈りが、この未知のドメインでも有効

→ より大規模な問題(15パズル,24パズル等)では *知識なし探索は指数爆発*

#+BEGIN_SMALLER
|------------------------+-------------------+----------------|
| Heuristics             | Search Time (sec) | Node Expansion |
|------------------------+-------------------+----------------|
| MNIST 8-puzzle         |                   |                |
| blind                  | 1.904             | 193924         |
| pdb                    | *1.780*           | *109096*       |
|------------------------+-------------------+----------------|
| blind                  | 1.751             | 201156         |
| pdb                    | *1.508*           | *111642*       |
|------------------------+-------------------+----------------|
| blind                  | 1.657             | 186767         |
| pdb                    | *1.215*           | *84561*        |
|------------------------+-------------------+----------------|
| blind                  | 1.514             | 183336         |
| pdb                    | *1.474*           | *82518*        |
|------------------------+-------------------+----------------|
| blind                  | 1.460             | 169907         |
| pdb                    | *0.685*           | *52084*        |
|------------------------+-------------------+----------------|
| blind                  | 1.489             | 130863         |
| pdb                    | *0.382*           | *26967*        |
|------------------------+-------------------+----------------|
| Hanoi (4 peg)          |                   |                |
| blind                  | 0.0008            | 55             |
| pdb                    | *0.0006*          | *17*           |
|------------------------+-------------------+----------------|
| LightsOut (4x4)        |                   |                |
| blind                  | 0.0159            | 952            |
| pdb                    | *0.0013*          | *27*           |
|------------------------+-------------------+----------------|
| Spiral LightsOut (3x3) |                   |                |
| blind                  | 0.0040            | 522            |
| pdb                    | *0.0026*          | *214*          |
|------------------------+-------------------+----------------|
| Mandrill 8-puzzle      |                   |                |
| blind                  | 2.759             | 335378         |
| pdb                    | *1.113*           | *88851*        |
|------------------------+-------------------+----------------|
#+END_SMALLER

* Conclusion

+ 入力:
  + ラベル無しの生の入力データで与えられた状態遷移規則
  + ラベル無しの初期状態・ゴールを表す画像ペア
+ 出力: ゴールを達成するためのプランを表す画像列

+ State AutoEncoder(SAE): Gumbel-Softmaxを用いたVAE

+ 主な貢献: *SAEによって生データから生成したシンボリック表現を用いてプランニング問題を解けることを実証*

+ */とても基礎的/* なプロトタイプ → 記号/非記号AI分野の様々な技術を取り入れることで */より発展/*

* Future Work (SAE)

SAEは命題の検出が可能 (状態s = p∧q∧r...)

→ 一階述語への一般化 (述語 p(a,b) )

→ オブジェクトの検出 (引数 a,b) が必要

→ 物体認識(R-CNN) などを内部で用いる より複雑なSAEの使用で対処可能

* Future Work (アクション生成)

個別の遷移をアクションとして扱うことしかできない (状態s → 状態t)

例:

: 個別の遷移        0011 → 0101
: 一般化された遷移  *01* → *10*

一般化されたアクションの検出 (述語 swap(tile1,tile2))

Model Acquisition [Konidaris et.al. 14;Cresswell et al 13] など 

* Future Work (問題ドメイン)

*SAE の実装を変えれば(原理的には)画像以外の任意の入力データに対応可能なはず*

+ テキスト用のAE: Li et al. "A hierarchical neural autoencoder for paragraphs and documents." (2015)
+ 音声用のAE: Deng, Li, et al. "Binary coding of speech spectrograms using a deep auto-encoder." Interspeech. 2010.

+ *Here's an Apple, Here's a pen → oh, ApplePen!*
+ SAEを学習してプランナで解く → *数千ステップの高速な言語レベル推論が可能に*

* 苦言

日本には記号的AIの研究者が居なさすぎて完全に砂漠状態 (OR除く)

意思決定と推論に重要な *抽象(abstraction)* や *緩和(relaxation)* といった概念

特に、対話技術とかを古典AIの概念と推論を用いずにやっているかぎり、人工無能以上には成り得ない

# JSAI は *技術* でなくて *目的* によってOSを分けるべき
# 
# + *ディープラーニング* OSと *論理* ではなく 

* AIMA 3rd Ed.                                                     :noexport:

1. Introduction
2. Intelligent Agents
3. Solving Problems by Searching
4. Beyond Classical Search
5. Adversarial Search
6. Constraint Satisfaction Problems
7. Logical Agents
8. First-Order Logic
9. Inference in First-Order Logic
10. Classical Planning
11. Planning and Acting in the Real World
12. Knowledge Representation
13. Quantifying Uncertainty
15. Probabilistic Reasoning over Time
16. Making Simple Decisions
17. Making Complex Decisions
18. Learning from Examples
19. Knowledge in Learning
20. Learning Probabilistic Models
21. Reinforcement Learning
22. Natural Language Processing
23. Natural Language for Communication
24. Perception
25. Robotics
26. Philosophical Foundations
27. AI: The Present and Future

