#+title: Classical Planning in Deep Latent Space: From Unlabelled Images to PDDL (and back) 
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+begin_outline-text-1
#+begin_center

#+begin_larger
_Masataro Asai_, Alex Fukunaga, The University of Tokyo
#+end_larger

#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* The */Killer App/* of AI Planning                                :noexport:


#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_larger
+ Places unreachable to mankind :: Nuclear Plant, Deep Space, Mars, Deep Sea
+ Where completeness, soundness and optimality matters :: 
     Satellite, Manufacturing, Logistics
+ Explainable systems :: 
     Rescue mission, Spaceship
#+end_larger

# [[sjpg:martian]]

#+end_span7
#+begin_span5

[[sjpg:gravity-m]]

#+end_span5
#+end_row-fluid
#+end_container-fluid

* Deep Neural Networks

[[png:deeplearning/1]]

** Human-competitive results in cognitive tasks

[[png:deeplearning/dl-image-task]]

* Deep Learning vs Planning

 Main differences: Purposes and the abstraction layer

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 *Machine Learning, Neural Networks* 
 
 for *Recognition, Reflex*
 + *Subsymbolic Input* (continuous)
   
   Images, Audio, unstructured text: 
 + *Soft Intelligence*:
   
   　 */Reflex Agent/, /Immediate/ actions*
   #+begin_smaller
   *Pavlov's dog* : food → drool

   *Autonomous Driving* : Pedestrian → Stop.

   *Machine Translation* : Sentence → Sentence

   *Eval. Function for Go* : board → win-rate
   #+end_smaller
   #+begin_larger
   ☺ Efficient 1-to-1 mapping
   
   ☹ Simple tasks
   #+end_larger
 #+end_span6
 #+begin_span6
 *Deliberation, Search*

 for *Planning, Game, Theorem Proving*
 + *Symbolic Input/Output*
   
   Logic, objects, induction rules
 + *Hard Intelligence by Logic:*

   　 */Multi-step/ strategies*
   
   #+begin_smaller
   *Rescue Robot* : actions → help the surviver

   *Theorem Proving* : theorems → QED

   *Compiler* : x86 instructions
   
   *Game of Go* : stones → Win
   #+end_smaller
   #+begin_larger
   ☺ Ordering constraint + complex tasks
   #+end_larger
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

+ AlphaGo = Subsymbolic (DLNN eval. function) + Symbolic (MCTS)

* Human-Competitive Systems

 AlphaGo = Subsymbolic (NN eval. func) + Symbolic (MCTS)
 + However, *domain-specific* -- specialized in Go, "Grids" / "Stones" are known
 + *Huge expert trace DB* --- Not applicable when data are scarse (e.g. *space exploration*)
 + */Is supervised learning necessary for human?/*
  
   *True intelligence should search / collect data by itself*

 DQN = Subsymbolic (DLNN) + Reinforcement Learning (DLNN)

Domain-independent Atari Game solver (Invader, Packman…), however:
 + RL Acting: Greedily follow the learned policy → *no deliberation!*
 + You can survive most Atari games *by reflex*
  
 # 実際 *Sokoban など論理思考ゲームでは性能が悪い* ↔ 倉庫番ソルバ

* Combining Symbolic AIs and Subsymbolic AIs

[[png:lecun]]

* Our Goal

#+begin_xlarge
#+begin_center
Deep Learning

＋

Classical Planning
#+end_center
#+end_xlarge

** Advantages

#+begin_xlarge
*/Perception/* based on DLNN
#+end_xlarge

--- Robust systems augmented by the latest DL tech

#+begin_xlarge
*/Decision Making/* based on Classical Planning
#+end_xlarge

--- *Better Theoretical Guarantee than Reinforcement Learning*

#+begin_center
*Completeness* (Finds solution whenever possible), */Solution Optimality/*
#+end_center

--- *Decision Making Independent from Learning*

#+begin_center
*/Unsupervised/* (No data required), *Explainable* (Search by logic)
#+end_center

# 今まではNNとの相性から強化学習が優勢だったが *もうその必要はない*

** 3x3 Sliding Tile Puzzle

#+begin_center
362880 configurations

4x4、5x5 puzzles : infeasible under blind search (memory exhaust)

Optimal solutions can be obtained by admissible heuristics
#+end_center

[[sjpg:puzzle]]

** Goal: Solving Imaged-Based 8-puzzle w/o Plan Example, Prior Explicit Knowledge

*DLNN + Classical Planning*

*No Prior Knowledge* : labels/symbols such as "9 tiles", "moving"

*No Plan Examples* : (AlphaGo) eval. function from expert plans → *admissible heuristics*

[[sjpg:puzzle]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example, Prior Explicit Knowledge

#+begin_xlarge
*/No Prior Knowledge/*

#+begin_alignright
*＝ /Domain-independent Planning/*
#+end_alignright
#+end_xlarge

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Tower of Hanoi

[[sjpg:hanoi]]
#+end_span6
#+begin_span4
Lights-Out

[[sjpg:lightsout]]
#+end_span4
#+end_row-fluid
#+end_container-fluid
* -

#+begin_xlarge
#+begin_center
System Overview
#+end_center
#+end_xlarge

** Input1: Training Inputs -- Image Pairs

Image pairs showing the before/after states of valid actions

[[png:overview/1]]

** Input1: Training Inputs -- Image Pairs

[[png:overview/2]]

** Input2: Planning Inputs -- Initial Image & Goal Image

Visual depiction of the initial state and a single goal state

[[png:overview/input2]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />
* Results (MNIST 8-puzzle)

8-puzzle using digits from MNIST database

[[png:results/mnist-plan]]

#+begin_larger
An instance whose the optimal solution length is known
#+begin_xlarge
#+begin_alignright
 → *31 step optimal plan*
#+end_alignright
#+end_xlarge
#+end_larger

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

MNIST 8-puzzle has cleanly separated objects -> This domain does not.

[[png:results/mandrill-intro]]

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

[[png:results/mandrill-plan]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solution*
#+end_alignright
#+end_xlarge

** Tower of Hanoi (3 disks, 4 disks)

Completely different puzzle problem can be solved with no change

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution* (7 steps,15 steps)
#+end_xlarge
#+end_alignright

** Lights Out

Completely different puzzle problem can be solved with no change

[[png:results/lights-out]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Twisted Lights Out

Does not assume grid-like structures

[[png:results/lights-out-skewed]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Handling the Noisy Input

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solutions*
#+end_alignright
#+end_xlarge

* Sure it works, how?

DLNN + Classical Planner

+ 1. Extracting knowledge from unlabelled images

  + *For what, and how?*

+ 2. Neural output is subsymbolic real-valued activations

  + Symbolic, discrete values, propositions? *Symbol Grounding*

+ 3. Machine-generated symbols are *not human-comprehensive*

  + *How to interpret these /foreign/ symbols?*

* Latent-Space Planner: *LatPlan*

We propose LatPlan *architechture*, and *LatPlanα*, an implementation

 [[png:overview/planning1]]

* Step 1: State Autoencoder (*/Core Contribution/*)

A neural network *bridging the Symbolic/Subsymbolic boundary*

 [[png:overview/planning2]]

** Step 1: State Autoencoder (*/Core Contribution/*)

[[png:train-state-ae]]

Trained SAE provides two functions:

+ $b = Encode(r)$ : *Function that maps a raw datum $r\;$ to a bit vector $b\;$ (propositions)*

+ $\tilde{r} = Decode(b)$ : *Function that maps a bit vector $b\;$ to a raw datum $\tilde{r}$*

* Step 2: Domain Acquisition (_/NOT our core contribution/_)

bitvector -> PDDL domain description

 [[png:overview/planning3]]

** PDDL generation in LatPlan α (_/NOT our core contribution/_)

Individual actions are mapped to PDDL actions (trivial domain acquisition)

#+begin_src lisp
 0011 → 0101

　　　↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; before-state
 :effect       (and (not (b1-false)) (b1-true)    ; state diff
                    (not (b2-true))  (b2-false)))
#+end_src

Conversion from a bit to a proposition:

#+begin_center
 $i$-th bit is 1 → Proposition ($b_i$ -true)

 $i$-th bit is 0 → Proposition ($b_i$ -false)
#+end_center

* Step 3: Solve the PDDL instance w/ off-the-shelf planner

 [[png:overview/planning4]]

* Step 4: Mapping the symbolic plan (human-incomprehensive) to images (human-comprehensive)

 [[png:overview/planning5]]

* *Our Core Contribution : SAE*

Obtain a bidirectional mapping between subsymbolic - symbolic representation

→ Use a *Variational Autoencoder with Gumbel-Softmax reparametrization*

*Core Contribution* : */Introduction of SAE/*

** Neural Network 101

[[png:deeplearning/1]]

** Neural Network 101

[[png:deeplearning/2]]

** Neural Network 101

[[png:deeplearning/3]]

** Stochastic Gradient Descent + GPU

[[spng:gradient-descent]]

Plus misc techniques e.g. *Batchnorm*, *Dropout*

#+begin_larger
*Pretty much everything is on the standard online tutorial / lecture cource / MOOP*

*Good libraries --- Tensorflow, Keras* --- you can learn in 1-2 months
#+end_larger

** Standard Classification / Mapping Tasks

Target Function $y^*=f^*(x)$
  
| Task                 | Input x  | Output y                           |
|----------------------+----------+------------------------------------|
| Image classification | Image    | Label (1=car, 2=cat, 3=monkey ...) |
| Translation          | Sentence | Sentence                           |
| Go eval. function    | State    | Number                             |

+ Actual output of the network $y=f(x)$

+ Learn to minimize $||y-y^*||$ by Backpropagation / SGD

** AutoEncoder : Unsupervised Learning

Auto = "self" --- Autoencoding = "encoding itself"

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ Target Function: Identity $x=f^*(x)$
+ Map the input $x\;$ to a *latent vector* $z$, then back to $x$
+ Dimension reduction (space compression): $X \rightarrow Z \rightarrow X$
+ You can extract the compression/decompression part: $Encode: x \mapsto z, Decode: z \mapsto x$
#+end_span6
#+begin_span6
[[png:static/autoenc]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
+ → However, */✘ Latent vector is real-valued, incompatible to classical planning/*
#+end_alignright

** Variational AutoEncoder (VAE)

An AutoEncoder that *enforce a certain distribution* on $Z \subset \mathbb{R}^n$ over the dataset $X$

#+begin_quote
You have $X=$ { 10k images of apples }. If you train a VAE on $X$, then $z = Encode(X) \approx N(\mu,\sigma)$ for some $\mu,\sigma \in \mathbb{R}^n$.
#+end_quote

VAE needs a *reparametrization trick* because random distributions are non-differentiable.

#+begin_quote
Reparametrization for $N(\mu,\sigma)$: $\mu + \sigma N(0,1)$

#+begin_center
\mu and \sigma are differentiable vectors, $N(0,1)$ is not.
#+end_center
#+end_quote

** Gumbel-Softmax Reparametrization (Jang, Gu, ICLR2017)

A reparametrization trick for *categorical distribution*: 1-hot vector e.g.  $\langle 0,0,0,1,0,0 \rangle$ .

Below: Represent an MNIST image with 30 variables of 8 categories.

#+begin_center
 #+begin_html
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+end_html
#+end_center

#+begin_larger
#+begin_center
Key idea: *These categorical variables are /directly/ usable*

*as a source of PDDL/SAS*

In particular, *2 categories → propositional variables (true/false)*
#+end_center
#+end_larger


** Step 1: State Autoencoder (*/before training/*)

 [[png:sae/state-ae-before]]


** Step 1: State Autoencoder (_/after training/_)

 [[png:sae/state-ae]]

** Gumbel-Softmax: Differential Approximation of Gumbel-Max

#+begin_larger
It uses *annealing* to approximate discrete vectors
#+end_larger

#+begin_smaller
Gumbel-Max: Method for drawing one-hot vector sample ($z$) from category probability ($x$)

+ E.g.: $x=[0.1, 0.1, 0.8] \rightarrow z = [1,0,0] \text{or} [0,1,0] \text{or} [0,0,1]$

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ argmax is non-differentiable → softmax approximation (differentiable)

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ Temparature $\tau \rightarrow 0$ , $z\rightarrow \text{one-hot vector}$

  # \[
  # \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  # \]
#+end_smaller

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span8
#+begin_center
[[png:sae/gumbel]]
#+end_center
#+end_span8
#+begin_span2

#+end_span2
#+end_row-fluid
#+end_container-fluid

#+begin_note
Maddison et. al., 2014
#+end_note

* Why bother the off-the-shelf planner? Shouldn't the blind search do?

*Domain-independent heuristics works, /SURPRISINGLY!/*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ This is *NOT* a trivial finding!

  Heuristics are...

  + taylored for *man-made* domains
  
  + assuming a *certain structure*

  PDB may even sometimes lose to Blind on IPC instances (Edelkamp 12)

+ *Would allow to solve the more difficult problems (future work)*
#+end_span6
#+begin_span6
#+begin_smaller
|------------------------+----------+----------+---------|
| /                      |        < |        > | <>      |
|                        |          |      <r> |         |
| Expanded nodes         | Dijkstra |   A*+PDB | Speedup |
|------------------------+----------+----------+---------|
| MNIST 8-puzzle         |   193924 | *109096* | x2      |
| MNIST 8-puzzle         |   201156 | *111642* | x2      |
| MNIST 8-puzzle         |   186767 |  *84561* | x2      |
| MNIST 8-puzzle         |   183336 |  *82518* | x2      |
| MNIST 8-puzzle         |   169907 |  *52084* | x3      |
| MNIST 8-puzzle         |   130863 |  *26967* | x5      |
|------------------------+----------+----------+---------|
| Hanoi (4 peg)          |       55 |     *17* | x3      |
|------------------------+----------+----------+---------|
| LightsOut (4x4)        |      952 |     *27* | x30     |
|------------------------+----------+----------+---------|
| Spiral LightsOut (3x3) |      522 |    *214* | x2.5    |
|------------------------+----------+----------+---------|
| Mandrill 8-puzzle      |   335378 |  *88851* | x4      |
|------------------------+----------+----------+---------|
#+end_smaller
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_larger
#+begin_alignright
→ */Leverage the effort from ICAPS community!/*
#+end_alignright
#+end_larger

# #+begin_larger
# PDB: Pattern DataBase ヒューリスティクス
# 
# 注: *プランニングでは理論保証付き下界関数のことをヒューリスティック関数と呼ぶ*
# #+end_larger

* Conclusion

+ Input: Unlabelled pairs of images, initial image, goal image
+ Output: Visualized plans to achieve the goal
+ State AutoEncoder(SAE): VAE with Gumbel-Softmax
+ */Contribution/* : *SAE generates /propositions/ from raw data*

  → *compatible to the symbolic classical planners*
+ Latplan α : *A prototype made /as simple as possible/*

  → Can leverege from the future development of both symbolic/subsymbolic AI research

#+begin_larger
Arxiv 1705.00154 : *Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary.*
#+end_larger

* Future Work (SAE)

SAE can generate propositional symbols (state $s = \{p,q,r\ldots\}$)

+ 1st-order logic (predicate $p(a,b)$ )

+ We need *object recognition from images* (parameters $a,b$)

+ SAE with networks for object recognition (e.g. R-CNN) should achieve this

* Future Work (input format)

LatPlan is an *architecture*

Any systems that use SAE is a LatPlan implementation

*With a different SAE impl., you should be able to reason about different raw data*

+ AutoEncoders for *unstructured text* [Li et.al. 2015], *audio* [Deng, Li, et al. 2010]
+ Examples:
  + *This is an apple, this is a pen → oh, ApplePen!* (ugh embarassing)
    
    when actions resembling "word concatenation" was learned
+ SAE will bring subsymbolic reasoning to a whole new level:
  
  *1k steps of optimal reasoning over natural language, powered by ICAPS*

#+begin_note
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+end_note

* I expect mixed responses such as...

#+begin_xlarge
+ Wait, what!? You /solved/ the symbol grounding!?
+ Huh, I hate deep learning hype, NN cannot be trusted.
+ This is not finding symbols.
+ This isn't a domain-acquisition.^* / symbol grounding.
#+end_xlarge

These are the results of confusions in an unexplored area.

(^* I actually received these responses)
* Did we find symbols? It doesn't sound like what I think symbols are

#+begin_smaller
You /solved/ the symbol grounding!? / This is not finding symbols. / This isn't a domain-acquisition.
#+end_smaller

*PDDL implies there are several kinds of symbols and we solved only /one/ issue*

+ Each issue requires a different approach. LatPlan should be combined with these work.

  |                        | <c>                |
  | Types of symbols       | addressed by       |
  |------------------------+--------------------|
  | Propositions           | SAE                |
  | Object labels          | Computer Vision    |
  | Predicates (relations) | -                  |
  | Actions                | Domain Acquisition |

* Did we find symbols? Why not individual pixels? Why DL?

*Individual pixels lacks generalization*

+ Noise / variations can make the data entirely different

  [[png:results/noise]]

+ must acquire the *generalized features*

+ = a nonlinear function that recognize the entanglements between multiple pixels

* SAE implementation in LatPlan α

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

　

+ Why full-connected layers ? ::
             Main focus is on *whether propositions made by SAE are feasible*
             
             *→No complication due to CNN, ResNet, etc...*
             
+ Training on 8-puzzle ::
               *12000 images* out of entire states (362880) → *Generalization*

* Does it have something to do with symbolic planning (BDDs) ?

No.

* Domain Acquisition implementation in LatPlan α (_/NOT our core contribution/_)

_Entire transitions $R$_ → $Encode(R)$ → PDDL

Why? → *Trivial domain acquisition, no generalization*

: Ground      actions 0011 → 0101  (state variables are fully specified)
: Generalized actions *01* → *10*  (state variables are partially specified)

+ LatPlanα: No generalization wrto domain acquisition ::

     Main focus is on */SAE/: whether propositions made by SAE are /feasible/*
             
     *→No complication due to domain acquisition*
     
     *Developping a generalizer is an entirely different topic*, we leave it to existing work

+ We made flour and demonstrated a sugarless cookie with it. ::

     Others study how to make the most beautiful piece of chocolate cake from given flour

     --- which is future work.

     Domain acquisition typically requires exisiting models (such as Semi-MDP)

     We made *inputs* for existing work.

#+begin_note
[Konidaris et.al. 14; Cresswell et al 13]
#+end_note

* When Latplan returns a /wrong/ solution?

*Machine learning may contain errors* (convergence /only on/ $t\rightarrow \infty$, not on real time)

+ Images → Fraud symbols/model/graph

+ *Optimal path on a fraud graph* or *graph disconnected*
  
  A* completeness, soundness, optimality

+ Fraud visualized plan (noisy) / no plan found

#+begin_center
#+begin_larger
LatPlan may make */wrong observations/* but no */wrong decisions/*
#+end_larger

BTW, "correctness" is defined by error prone observations by humans anyways ...
#+end_center

#+begin_alignright
 (completeness, optimality) → better reliablility than Reinforcement Learning
#+end_alignright

** Reinforcement Learning

Not only *perception* but *decision making also depends on training*

+ */Each training result does not have admissibility/*

+ */When the learned policy is wrong, the solution could be suboptimal/*

#+begin_quote
... AlphaGo was unprepared for Lee Sedol’s Move 78 because it
didn’t think that a human would ever play it.

#+begin_alignright
Cade Metz. "In Two Moves, that Redifined the Future." /Wired/, 2016
#+end_alignright
#+end_quote

#+begin_center
#+begin_larger
RL may make *wrong decisions*.
#+end_larger
#+end_center

* Why symbols?

Symbols are strong abstraction mechanisms becasue

+ Meanings do not matter ::
     You do not have to understand it: Does a symbol $X$ mean an apple or a car?
 
     Logical reasoning can be performed by mechanical application of rules
     
     + Domain-independent planning : *mystery* vs *nomystery*

       Logistic domains where *symbol names are mangled* (truck → shark)

+ Composable :: 
     A latent vector is a conjunction (and)
     
     Heuristic functions use modus ponens to derive guidance

* More details

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ Training: ~30 min
+ Solving: ~3 sec

** State AutoEncoder (Train data)

1: $x$ 2: $z$ 3: $y$ 4: $round(z)$ 5: $Decode(round(z))$

[[spng:experiment/autoencoding_train]]

** State AutoEncoder (Validation)

1: $x$ 2: $z$ 3: $y$ 4: $round(z)$ 5: $Decode(round(z))$

[[spng:experiment/autoencoding_test]]

** State AutoEncoder

Input 2: intial/goal images

[[spng:experiment/init_goal]]

** PDDL Domain Definition

Examples in $N=25$ (in the paper we bypassed PDDL-SAS converter though)

#+begin_src lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

** Results in one place

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6

[[png:results/mnist-plan]]

[[png:results/mandrill-plan]]

#+end_span6
#+begin_span6

[[png:results/hanoi3]]

[[png:results/hanoi4]]

[[png:results/lights-out]]

[[png:results/lights-out-skewed]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Fast Downward Log Trace (Search Statistics)                     :noexport:


#+begin_example
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+end_example

