#+title: Classical Planning in Deep Latent Space
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+BEGIN_outline-text-1
#+BEGIN_CENTER
東京大学大学院 博士2年

総合文化研究科　(渋谷駒場キャンパス)

学振DC2

浅井 政太郎
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* もくじ

+ Background -- 専攻分野 -- AIプランニングへのイントロダクション
+ CV
+ IJCAI投稿論文 -- 深層学習 + AIプランニング

* Background -- 専攻分野 -- AIプランニングへのイントロダクション

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

  #+BEGIN_RESUME
  And let me introduce these robots.
  The guy in the left is Astro boy.
  #+END_RESUME

*** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/2]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 As you know, he is a famous manga superhero invented by Tezuka Osamu in 50s,
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/1]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 and he can think, hear, speak, act. he also has emotions.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/2]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
  In contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  His name is T-52 Enryu, developped by a Japanese company Temzak.
  He is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  Well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/3]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 But does he have feelings or can he think? Can he even move around by his own?
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/final]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 No. It requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. It is more like a
 super-sophisticated shovel car.
 #+END_RESUME

** 実際の大規模災害では非実用的 --- 操縦士が足りない!

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+END_SPAN2
 #+BEGIN_SPAN10
 [[jpg:static/tsunami]]
 #+END_SPAN10
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_LARGER
 #+BEGIN_ALIGNRIGHT
 + そのままでは役に立たない!
 #+END_ALIGNRIGHT
 #+END_LARGER

 #+BEGIN_RESUME
 Now the problem is : It's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in Japan.
 The key resource is human ---
 These special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+END_RESUME

*** 操縦士を増やせない -- Human Resource and Training

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN4
  [[png:rescue/1]]
 #+END_SPAN4
 #+BEGIN_SPAN8

   + ✘ /時間/ がかかる :: 訓練に ＞100時間, *必要な時だけ増やす* のは不可能
   + ✘ /￥￥￥￥/ がかかる :: 訓練官、訓練場所、訓練用具
   + ✘ 技術は /維持が重要/ :: 定期的な再訓練、長期的コスト、さらなるマニー
   + ✘ 平時は /無駄/ な技術 :: 普段は意味がない -- 無駄なマニー!
 #+END_SPAN8
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 In a natural disaster, we need as many experienced operators as possible.
 However, it is virtually impossible due to several reasons. 

 First, training takes time.
 It is impossible to quickly increase the number of operators as needed, at the time of disaster.

 Second, the money matters.
 Training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 Third, Skills need to be updated and maintained.
 You know, how about preparing the large number of operators in advance?
 No, the society cannot torelate the cost of keep training them.
 Operators may lose the skills and skills may become outdated.

 Finally, in a normal situation, those skills are useless.
 It forces the society to waste a great amount of extra money.
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/1]]

 #+BEGIN_RESUME
 研究テーマのプランニングは、ロボットに、人間の助けを借りず、いかに自律して行動させるかを扱います。
 これをモデル化したプランニング問題は、具体的な行動の列を求める 組合せ最適化問題です。

 プランニング問題のタスクは、
 センサーから初期状態とゴールを受け取って、被災者を助ける正しい手順を出力することです。

 たとえば、この図では男性が瓦礫に埋まって助けを求めています。
 プランニング機能のあるロボットは、コレに対して「男性を助けよ」という大まかな指示を受けます。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/2]]

 #+BEGIN_RESUME
 指示の内容には、図のように初期状態とゴール、許可された行動のリストが入っています。
 ロボットは、自動プランニングにより、人間の代わりに適切な行動を組み立てて、ゴールを自動で達成します。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/final]]

 #+BEGIN_RESUME
 プランニングは汎用な枠組みなので、災害救助以外にも様々な問題に適用することができます。
 現実の応用例では「宇宙探査機運行問題」や「企業ネットワーク脆弱性問題」も表現できます。

 このように、プランニングは、難しい問題を汎用性を失わずに解くことを目指します。
 #+END_RESUME

** AIの使いドコロ  :noexport:

 + 人では不可能な作業の代替 :: 危険な環境, 宇宙空間・深海, 24時間対応, マイクロ秒応答
 + コストのかかる専門技師の代替・自動化 :: 機械工作, 人工衛星運営(専門家会議の時給が高い!)
 + ミスの許されない完璧な理論保証の求められる問題の求解 :: 半導体のバグ検証システム(生産を始めると止められない)

** AIと自動プランニング の位置づけ -- /理論/ と /実応用/ の中間

 緑は /理論/ 、オレンジは /実応用/ 、 AI はその橋渡し (どれともかぶらない部分もある)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning2]]
* プランニング問題 (決定的,完全情報) -- Blocksworld

#+HTML: <embed src="img/plan.svg" type="image/svg+xml"  />

** アクション = 条件付き状態遷移

#+BEGIN_CENTER
#+BEGIN_XLARGE
アクション (move ?X ?Y)
#+END_XLARGE
#+END_CENTER

#+BEGIN_CENTER
*?X*, *?Y* : 変数。 値 *BLOCK-A*, *BLOCK-B* などを適用して使う

*前提条件* と *効果* で構成される
#+END_CENTER
#+BEGIN_QUOTE
*前提条件* が満たされた時…

命題 (clear *?X*) : 積み木 *?X* の上に何も置かれていない

命題 (clear *?Y*) : 積み木 *?Y* の上に何も置かれていない

*効果* を適用

⇒ 命題 (on *?X* *?Y*) を追加 : *?X* が *?Y* の上に移動

⇒ 命題 (clear *?Y*) を削除 : *?Y* は clear ではなくなる
#+END_QUOTE

** *PDDL* : Planning Domain Description Language                   :noexport:

現在も International Planning Competition の入力形式として使われている。

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN8
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN8
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_NOTE
宇宙探査機 NASA DS1 上の Remote Agent 自動航行システム でも
 "DDL" という名で 似たような記述言語があったようだ
#+END_NOTE

** プランニング = グラフ探索

*ノード* : 状態 = 命題の集合 ⇒ =(on A B)=, =(clear A)= など

*辺*     : アクション ⇒ =(move A B)= 等

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ヒューリスティック探索 A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  



** [一般向け] Q. はやりのDeep Learningとの違いは?

 A. レイヤが違う

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *機械学習・Neural Networks* 
 
 for *認識・反射*
 + 入力 は *Subsymbolic* (連続値)
   
   画像、音声、非構造化テキスト: 
 + *直感/脊髄反射的知能*:
   
   　 *_直後_ の行動の決定*
   #+BEGIN_SMALLER
   *パブロフの犬* : 餌→よだれ

   *自動運転* : 赤信号,人 → 止まる.

   *翻訳* : 文章 → 文章

   *囲碁局面の評価関数* : 局面 → 勝率
   #+END_SMALLER
   ☺ 効率よく 1-to-1 mapping
   
   ☹ 単純作業
 #+END_SPAN6
 #+BEGIN_SPAN6
 *推論・探索*

 for *プランニング・ゲーム・定理証明*
 + 入出力は *Symbolic*
   
   論理 オブジェクト ルール
 + *論理・推論による知能:*

   　 *_未来に渡る_ 戦略の決定*
   
   　 (戦略 = 行動の *列や木*)
   #+BEGIN_SMALLER
   *レスキューロボ* : ゴール = 被災者生存

   *証明器* : ゴール = QED

   *コンパイラ* : 命令列の生成
   
   *囲碁,将棋* : ゴール = 勝利
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ 時間的依存関係を含む論理の組み合わせ
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

+ AlphaGo = Subsymbolic (DLNNによる評価関数の学習) + Symbolic (UCT-MCTSによる探索)

** 既存の有名システム

+ AlphaGo = Subsymbolic (DLNNによる評価関数の学習) + Symbolic (UCT-MCTSによる探索)
  + ただし *囲碁に特化*, かつ *膨大な棋譜が必要*
  + 自律的なエージェントは *未知の状況に推論により対処しなくてはならない* → まだ完璧ではない
+ DQN = DLNN (*Subsymbolic*) + Reinforcement Learning (*Subsymbolic*)
  + 様々な Atari Game につかえる汎用的なフレームワーク (Invader, Packman…) だが
  + ほとんどのゲームは *脊髄反射的な操作で長く生き残ることが出来る*
  + *Atari をプレイする上で 複雑な論理思考能力は必要ない*
  + だからこそRLで成功した

#+BEGIN_NOTE
DLNN: Deep Learning Neural Network

UCT-MCTS: Monte Carlo Tree Search + Universal Confidence Bound applied on Trees
#+END_NOTE

* CV

#+BEGIN_XLARGE
#+BEGIN_CENTER
配布
#+END_CENTER
#+END_XLARGE

* 高度に知的な機械を作るには → DeepLearning + 論理と推論

#+BEGIN_CENTER
#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
ディープラーニングのみ

↓

虫程度の知能を持った

*反射的な機械*
#+END_SPAN5
#+BEGIN_SPAN2
　

vs

　
#+END_SPAN2
#+BEGIN_SPAN5
DL + *論理、推論、思考*

↓

目標を達成するために

*論理で戦略を練る機械*

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID
#+END_CENTER

[[png:planning-deeplearning]]
* ゴール

#+BEGIN_XLARGE
#+BEGIN_CENTER
State of the Art

Deep Learning 

＋

State of the Art

Classical Planning
#+END_CENTER
#+END_XLARGE

* スライディング タイル パズル (8-Puzzle)

空きパネルとそれ以外を移動させることで絵を完成させるパズル

[[sjpg:puzzle]]

#+BEGIN_ALIGNRIGHT
*古典的なAI問題として知られている*

可能な曲面の数は 362880 個

4x4の15-パズル、5x5の24-パズルはさらに難しい
#+END_ALIGNRIGHT

* ヒント・棋譜なし 画像のみ で 8-Puzzleを解く

8-Puzzle を解く論理に基づくAIを作る

 *ヒント・棋譜なし* : *棋譜から学習した勘で解くAlphaGoと異なる*

[[sjpg:puzzle]]

** ヒント・棋譜なし 画像のみ で 8-Puzzleを解く

[[png:overview/1]]

** ヒント・棋譜なし 画像のみ で 8-Puzzleを解く

[[png:overview/2]]

** ヒント・棋譜なし 画像のみ で 8-Puzzleを解く

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

* Introduction

#+BEGIN_XLARGE
#+BEGIN_CENTER
There's No Silver Bullet!!
#+END_CENTER
#+END_XLARGE

* Deep Neural Networks

とてもはやっている

　

　

[[png:deeplearning1]]

** Deep Neural Networks

とてもはやっている

ベクトル (データ) と 行列W (重み) の掛け算 

　

[[png:deeplearning2]]

** Deep Neural Networks

とてもはやっている

ベクトル (データ) と 行列W (重み) の掛け算 

→ 出力の誤差=微分を使ってWを更新 → 学習完了

[[png:deeplearning3]]


** 認知タスクで人間に匹敵する精度

[[png:dl-image-task]]

** 認知タスクで人間に匹敵する精度

[[png:dl-nlp-task]]

** ニューラルネットの役割

#+BEGIN_CENTER
「直感的な」問題を解く *関数* を学習すること
#+END_CENTER

+ 求めるべき関数 $y^*=f^*(x)$
  
  | タスク   | 入力x      | 出力y                      |
  |----------+------------+----------------------------|
  | 画像分類 | 画像       | ラベル(車、ネコ、猿・・・) |
  | 翻訳     | 文章(日)   | 文章(英)                   |
  | 未来予測 | フレーム列 | 次のフレーム               |

+ NNが表す関数　 $y=f(x)$

#+BEGIN_CENTER
+ 学習 ≡ 誤差 $||y-y^*||$ を最小化する最適化問題
#+END_CENTER

** NNは複雑な問題を魔法のように解くことが出来る

#+BEGIN_LARGER
なぜなら

#+BEGIN_indent
  + 人間は賢くてニューロンで動く し、
  + ニューロンある = 賢さの証明 だし、
  + 賢ければ何でも出来て当然 だし、
  + 将来はシンギュラリティに溢れてて当然。
  + ...
  + ハァ?
#+END_indent
#+END_LARGER

** 

[[png:dl-silver-bullet]]

** NNは複雑な問題を魔法のように解くことができる?

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
+ *出来る派の意見:*
+ 人間は賢くてニューロンで動く
+ ニューロン = 賢い
+ 賢い機械はスゴイからニューロンだ
+ 脳科学でシンギュラっちゃうぜ！

  ※ 画像はイメージ
  
  [[spng:ai_pet_family]]
#+END_SPAN6
#+BEGIN_SPAN6
+ *出来ない派の意見:*
+ プラナリアも神経系を持つが賢い??
+ *Is humanity /so/ smart?*
+ *Not necessarily↓*

  ※ 画像はイメージ
  
  [[spng:mizuho]]
  
  [[sjpg:trump]]
#+BEGIN_ALIGNRIGHT
#+END_ALIGNRIGHT
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** No Silver Bullet: NNで複雑な問題を魔法のように解くことはできない・・・と思われる2 :noexport:

+ 出来る派のもう少しマシな意見:
  + NN は Turing完全, アナログNNは Super Turing (Siegelmann, 95, Science)
  + 二段以上のNNは 十分な数のノードがあれば どんな関数でも表現可能

+ *出来ない派のもう少し真面目な反論*:
  + *表現できる != 学習できる*
  + *構造の単純な関数しか学習できない*
    + *Gradient Descent の亜種で解けるような関数*
    + *局所解は大域最適解である??*

*** Gradient Descent (再急降下法)

傾きの大きい方向に向かって進む

[[spng:gradient-descent]]

#+BEGIN_CENTER
*一般には: 最適解でないところに到達する可能性がある*

*NNでは: 局所解はほぼ確実に大域最適解である == 無視*
#+END_CENTER

#+BEGIN_NOTE
SGDでも基本的な想定は一緒
#+END_NOTE

*** 進化計算などで解かれるRastrigin関数 (例)

#+BEGIN_CENTER
こういう関数は SGD では解けない

→ *NNでは学習できない種類の構造も存在する*
#+END_CENTER
   
[[sjpg:rastrigin]]

** No Silver Bullet: NNで複雑な問題を魔法のように解くことはできない・・・と思われる3

+ 出来ない派のもう少し真面目な反論2:
  + *認知タスクと比べ、論理思考タスクは人間にも難しい*
    + *人間の物体認識: 1秒以下*
    + *大学入試数学の証明問題: 25分*
    + 明らかに *難しさの質に差がある*
  + 難しさの質というのはどうやって測る?
    + 理論的解析: *計算量理論* (NP困難とか)
  # + *論理思考タスクは計算量理論的に困難な問題が多数*
  #   + *NP困難以上: 最悪指数時間*
  #   + *← 学習に指数時間かかる = 解けないのと同じ*

*** 学習が終わるのは

[[sjpg:利根川]]

** 

#+BEGIN_XLARGE
#+BEGIN_CENTER
ニューラルネットは

銀の弾ではない

従って、ブームではあるが・・・
#+END_CENTER
#+END_XLARGE

** 

[[sjpg:fukashigi]]

* ゴール

#+BEGIN_XLARGE
#+BEGIN_CENTER
State of the Art

Deep Learning 

＋

State of the Art

Classical Planning
#+END_CENTER
#+END_XLARGE


* システム概要

 [[png:overview/planning]]

** State Autoencoder

 [[png:overview/state-ae]]

** Autoencoder

#+BEGIN_CENTER
*教師なし学習*

入力空間 *S* を Latent Space *L* に *圧縮*

かつ *S* に *展開* して *元の画像に損失無く戻す。*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
→ *データ* $x$ を *Latent vector* $z$ に変換/逆変換するNNを学習
#+END_ALIGNRIGHT

** Deep Autoencoder

 いろいろな追加技術を使うことでDeepにできる → *より圧縮できる*

 Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

 [[png:static/deep-ae]]

** State Autoencoder

 [[png:overview/state-ae]]

** Gumbel-Softmax (Jang, Gu, ICLR2017?)

 *入力をカテゴリカル分布にマップする* Activation Function 

#+BEGIN_CENTER
 #+BEGIN_HTML
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-OBY7yjnWj9k/WCK6i_l0R9I/AAAAAAAAFLY/jCJwLNuPMecbvAB719g6VhAypmoDH6gswCLcB/s1600/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-WySijJ91Oa8/WCK6jFdXluI/AAAAAAAAFLc/CpaGjhd5lPwUdT6FdGNPQKRlyFhYvcwVQCLcB/s1600/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-tGqhaoX1a4Y/WCK6izWaixI/AAAAAAAAFLU/QRr6CzXET18_-c8hlx89QOkSQ3HoRH2DwCLcB/s1600/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+END_HTML
#+END_CENTER

 #+BEGIN_NOTE
 ICLR17に *投稿中*, 2/3に採択結果判明
 #+END_NOTE

** Gumbel-Softmax

学習中に温度を下げていくことで *始めは自由に学習*

*そののち、精度を保ったまま中間層の分布をカテゴリカルに近づける*

[[spng:gumbel]]

#+BEGIN_ALIGNRIGHT
*カテゴリー2 → 0か1 の離散的分布になる → 命題にマップ可能*
#+END_ALIGNRIGHT

** Entire System

 [[png:overview/planning]]

* 評価

GTX1070, PhenomII X6 1060T (3.4GHz overclock), 16GB Mem

+ Fast Downward :: LMcut vs Blind heuristics, A*

+ State AutoEncoder :: Tensorflow, Keras, Adam optimizer (learning rate:0.001)

  784(84x84)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(25,GumbelSoftmax)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →784(84x84) (loss: Binary crossentropy)

** 所要時間(目安)

 新しいシステムなので対戦相手が居ない...

 + State Autoencoder 学習時間: 1時間程度
 + MSDD Operator Acquisition (Lisp SBCL): 1時間程度
 + PDDL変換 (Lisp SBCL): 一瞬
 + Fast Downward: 2時間, メモリ1G程度で終了

** State AutoEncoder

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像

[[spng:experiment/autoencoding_test]]

#+BEGIN_ALIGNRIGHT
きちんと学習できている
#+END_ALIGNRIGHT

** State AutoEncoder

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

#+BEGIN_SRC
  -rw-rw-r-- 1 guicho guicho  31M 2017-01-20 00:10 domain-all.pddl
#+END_SRC

#+BEGIN_SRC lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+END_SRC

** Fast Downward Log Trace (Search Statistics)

#+BEGIN_SRC
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+END_SRC

** State of the Art な枝刈り技術が /この未知のドメインでも有効/

|                 | LMcut | Blind |
| Node Evaluation | 1140  |       |
| Memory Usage    | 1GB   |       |

** Plan Results

[[spng:experiment/plan]]

* Conclusion

+ Proposed a new system that solves a combinatorial problem proposed as raw images
+ Should be a milestone toward symbol grounding problem

