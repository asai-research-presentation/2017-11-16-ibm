#+title: 
#+author: 
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+begin_outline-text-1
#+begin_center

#+begin_larger
_Masataro Asai_, Alex Fukunaga, The University of Tokyo
#+end_larger

#+begin_xlarge
Classical Planning

in Deep Latent Space:

From Unlabelled Images

to PDDL (and back)
#+end_xlarge

#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* The */Killer App/* of AI Planning                                :noexport:


#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_larger
+ Places unreachable to mankind :: Nuclear Plant, Deep Space, Mars, Deep Sea
+ Where completeness, soundness and optimality matters :: 
     Satellite, Manufacturing, Logistics
+ Explainable systems :: 
     Rescue mission, Spaceship
#+end_larger

# [[sjpg:martian]]

#+end_span7
#+begin_span5

[[sjpg:gravity-m]]

#+end_span5
#+end_row-fluid
#+end_container-fluid

* Deep Neural Networks

[[png:deeplearning/1]]

** Human-competitive results in cognitive tasks

[[png:deeplearning/dl-image-task]]

* Deep Learning vs Planning

 Main differences: Purposes and the abstraction layer

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 *Machine Learning, Neural Networks* 
 
 for *Recognition, Reflex*
 + *Subsymbolic Input* (continuous)
   
   Images, Audio, unstructured text: 
 + *Soft Intelligence*:
   
   　 */Reflex Agent/, /Immediate/ actions*
   #+begin_smaller
   *Pavlov's dog* : food → drool

   *Autonomous Driving* : Pedestrian → Stop.

   *Machine Translation* : Sentence → Sentence

   *Eval. Function for Go* : board → win-rate
   #+end_smaller
   #+begin_larger
   ☺ Efficient 1-to-1 mapping
   
   ☹ Simple tasks
   #+end_larger
 #+end_span6
 #+begin_span6
 *Deliberation, Search*

 for *Planning, Game, Theorem Proving*
 + *Symbolic Input/Output*
   
   Logic, objects, induction rules
 + *Hard Intelligence by Logic:*

   　 */Multi-step/ strategies*
   
   #+begin_smaller
   *Rescue Robot* : actions → help the surviver

   *Theorem Proving* : theorems → QED

   *Compiler* : x86 instructions
   
   *Game of Go* : stones → Win
   #+end_smaller
   #+begin_larger
   ☺ Ordering constraint + complex tasks
   #+end_larger
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

+ AlphaGo = Subsymbolic (DLNN eval. function) + Symbolic (MCTS)

* Human-Competitive Systems

 AlphaGo = Subsymbolic (NN eval. func) + Symbolic (MCTS)
 + However, *domain-specific* -- specialized in Go, "Grids" / "Stones" are known
 + *Huge expert trace DB* --- Not applicable when data are scarse (e.g. *space exploration*)
 + */Is supervised learning necessary for human?/*
  
   *True intelligence should search / collect data by itself*

 DQN = Subsymbolic (DLNN) + Reinforcement Learning (DLNN)

Domain-independent Atari Game solver (Invader, Packman…), however:
 + RL Acting: Greedily follow the learned policy → *no deliberation!*
 + You can survive most Atari games *by reflex*
  
 # 実際 *Sokoban など論理思考ゲームでは性能が悪い* ↔ 倉庫番ソルバ

* Combining Symbolic AIs and Subsymbolic AIs

[[png:lecun]]

* Our Goal

#+begin_xlarge
#+begin_center
Deep Learning

＋

Classical Planning
#+end_center
#+end_xlarge

** Advantages

#+begin_xlarge
*/Perception/* based on DLNN
#+end_xlarge

--- Robust systems augmented by the latest DL tech

#+begin_xlarge
*/Decision Making/* based on Classical Planning
#+end_xlarge

--- *Better Theoretical Guarantee than Reinforcement Learning*

#+begin_center
*Completeness* (Finds solution whenever possible), */Solution Optimality/*
#+end_center

--- *Decision Making Independent from Learning*

#+begin_center
*/Unsupervised/* (No data required), *Explainable* (Search by logic)
#+end_center

# 今まではNNとの相性から強化学習が優勢だったが *もうその必要はない*

** 3x3 Sliding Tile Puzzle

#+begin_center
362880 configurations

4x4、5x5 puzzles : infeasible under blind search (memory exhaust)

Optimal solutions can be obtained by admissible heuristics
#+end_center

[[sjpg:puzzle]]

** Goal: Solving Imaged-Based 8-puzzle w/o Plan Example, Prior Explicit Knowledge

*DLNN + Classical Planning*

*No Prior Knowledge* : labels/symbols such as "9 tiles", "moving"

*No Plan Examples* : (AlphaGo) eval. function from expert plans → *admissible heuristics*

[[sjpg:puzzle]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example, Prior Explicit Knowledge

#+begin_xlarge
*/No Prior Knowledge/*

#+begin_alignright
*＝ /Domain-independent Planning/*
#+end_alignright
#+end_xlarge

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Tower of Hanoi

[[sjpg:hanoi]]
#+end_span6
#+begin_span4
Lights-Out

[[sjpg:lightsout]]
#+end_span4
#+end_row-fluid
#+end_container-fluid
* -

#+begin_xlarge
#+begin_center
System Overview
#+end_center
#+end_xlarge

** Input1: Training Inputs -- Image Pairs

Image pairs showing the before/after states of valid actions

[[png:overview/1]]

** Input1: Training Inputs -- Image Pairs

[[png:overview/2]]

** Input2: Planning Inputs -- Initial Image & Goal Image

Visual depiction of the initial state and a single goal state

[[png:overview/input2]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />
* Results (MNIST 8-puzzle)

8-puzzle using digits from MNIST database

[[png:results/mnist-plan]]

#+begin_larger
An instance whose the optimal solution length is known
#+begin_xlarge
#+begin_alignright
 → *31 step optimal plan*
#+end_alignright
#+end_xlarge
#+end_larger

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

MNIST 8-puzzle has cleanly separated objects -> This domain does not.

[[png:results/mandrill-intro]]

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

[[png:results/mandrill-plan]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solution*
#+end_alignright
#+end_xlarge

** Tower of Hanoi (3 disks, 4 disks)

Completely different puzzle problem can be solved with no change

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution* (7 steps,15 steps)
#+end_xlarge
#+end_alignright

** Lights Out

Completely different puzzle problem can be solved with no change

[[png:results/lights-out]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Twisted Lights Out

Does not assume grid-like structures

[[png:results/lights-out-skewed]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Handling the Noisy Input

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solutions*
#+end_alignright
#+end_xlarge

* Sure it works, how?

DLNN + Classical Planner

+ 1. Extracting knowledge from unlabelled images

  + *For what, and how?*

+ 2. Neural output is subsymbolic real-valued activations

  + Symbolic, discrete values, propositions? *Symbol Grounding*

+ 3. Machine-generated symbols are *not human-comprehensive*

  + *How to interpret these /foreign/ symbols?*

* Latent-Space Planner: *LatPlan*

We propose LatPlan *architechture*, and *LatPlanα*, an implementation

 [[png:overview/planning1]]

* Step 1: State Autoencoder (*/Core Contribution/*)

A neural network *bridging the Symbolic/Subsymbolic boundary*

 [[png:overview/planning2]]

** Step 1: State Autoencoder (*/Core Contribution/*)

[[png:train-state-ae]]

Trained SAE provides two functions:

+ $b = Encode(r)$ : *Function that maps a raw datum $r\;$ to a bit vector $b\;$ (propositions)*

+ $\tilde{r} = Decode(b)$ : *Function that maps a bit vector $b\;$ to a raw datum $\tilde{r}$*

* Step 2: Domain Acquisition

bitvector -> PDDL domain description

 [[png:overview/planning3]]

** PDDL generation in LatPlan α (an implementation of Latplan)

Individual actions are mapped to PDDL actions

#+begin_src lisp
 0011 → 0101

　　　↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; before-state
 :effect       (and (not (b1-false)) (b1-true)    ; state diff
                    (not (b2-true))  (b2-false)))
#+end_src

Conversion from a bit to a proposition:

#+begin_center
 $i$-th bit is 1 → Proposition ($b_i$ -true)

 $i$-th bit is 0 → Proposition ($b_i$ -false)
#+end_center

* Step 3: Solve the PDDL instance w/ off-the-shelf planner

 [[png:overview/planning4]]

* Step 4: Mapping the symbolic plan (human-incomprehensive) to images (human-comprehensive)

 [[png:overview/planning5]]

* *Our Core Contribution : SAE*

Obtain a bidirectional mapping between subsymbolic - symbolic representation

→ Use a *Variational Autoencoder with Gumbel-Softmax reparametrization*

*Core Contribution* : */Introduction of SAE/*

** Neural Network 101

[[png:deeplearning/1]]

** Neural Network 101

[[png:deeplearning/2]]

** Neural Network 101

[[png:deeplearning/3]]

** Stochastic Gradient Descent + GPU

[[spng:gradient-descent]]

Plus misc techniques e.g. Batchnorm, Dropout

Pretty much everything is on the standard online tutorial / lecture cource / MOOP

Good libraries --- Tensorflow, Keras

** Standard Classification / Mapping Tasks

Target Function $y^*=f^*(x)$
  
| Task                 | Input x  | Output y                           |
|----------------------+----------+------------------------------------|
| Image classification | Image    | Label (1=car, 2=cat, 3=monkey ...) |
| Translation          | Sentence | Sentence                           |
| Go eval. function    | State    | Number                             |

+ Actual output $y=f(x)$

+ Learn to minimize $||y-y^*||$ by Backpropagation / SGD

** AutoEncoder : Unsupervised Learning

Auto = "self" --- Autoencoding = "encoding itself"

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ Target Function: Identity $x=f^*(x)$
+ Map the input $x\;$ to a *latent vector* $z$, then back to $x$
+ Dimension reduction (space compression): $X \rightarrow Z \rightarrow X$
+ You can extract the compression/decompression part: $Encode: x \mapsto z, Decode: z \mapsto x$
#+end_span6
#+begin_span6
[[png:static/autoenc]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
+ → However, */✘ Latent vector is real-valued, incompatible to classical planning/*
#+end_alignright

** Variational AutoEncoder (VAE)

An AutoEncoder that *enforce a certain distribution* on $Z \subset \mathbb{R}^n$ over the dataset $X$

#+begin_quote
You have $X=$ { 10k images of apples }. If you train a VAE on $X$, then $z = Encode(X) \approx N(\mu,\sigma)$ for some $\mu,\sigma \in \mathbb{R}^n$.
#+end_quote

VAE needs a *reparametrization trick* because random distributions are non-differentiable.

#+begin_quote
Reparametrization for $N(\mu,\sigma)$: $\mu + \sigma N(0,1)$

#+begin_center
\mu and \sigma are differentiable vectors, $N(0,1)$ is not.
#+end_center
#+end_quote

** Gumbel-Softmax Reparametrization (Jang, Gu, ICLR2017)

A reparametrization trick for *categorical distribution*: 1-hot vector e.g.  $\langle 0,0,0,1,0,0 \rangle$ .

Below: Represent an MNIST image with 30 variables of 8 categories.

#+begin_center
 #+begin_html
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+end_html
#+end_center

#+begin_larger
#+begin_center
Key idea: *These categorical variables are /directly/ usable*

*as a source of PDDL/SAS*

In particular, *2 categories → propositional variables (true/false)*
#+end_center
#+end_larger


** Step 1: State Autoencoder (*/before training/*)

 [[png:sae/state-ae-before]]


** Step 1: State Autoencoder (_/after training/_)

 [[png:sae/state-ae]]

** Gumbel-Softmax: Differential Approximation of Gumbel-Max

Gumbel-Max: Method for drawing one-hot vector sample ($z$) from category probability ($x$)

#+begin_smaller
+ E.g.: $x=[0.1, 0.1, 0.8] \rightarrow z = [1,0,0] \text{or} [0,1,0] \text{or} [0,0,1]$

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ argmax is non-differentiable → softmax approximation (differentiable)

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ Temparature $\tau \rightarrow 0$ , $z\rightarrow \text{one-hot vector}$

  # \[
  # \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  # \]
#+end_smaller

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span8
#+begin_center
[[png:sae/gumbel]]
#+end_center
#+end_span8
#+begin_span2

#+end_span2
#+end_row-fluid
#+end_container-fluid

#+begin_note
Maddison et. al., 2014
#+end_note

* Why bother the off-the-shelf planner? Shouldn't the blind search do?

*Domain-independent heuristics works, /SURPRISINGLY!/*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ This is *NOT* a trivial finding!

  Heuristics are...

  + taylored for *man-made* domains
  
  + assuming a *certain structure*

  PDB may even sometimes lose to Blind on IPC instances (Edelkamp 12)

+ *Would allow to solve the more difficult problems (future work)*
#+end_span6
#+begin_span6
#+begin_smaller
|------------------------+----------+----------+---------|
| /                      |        < |        > | <>      |
|                        |          |      <r> |         |
| Expanded nodes         | Dijkstra |   A*+PDB | Speedup |
|------------------------+----------+----------+---------|
| MNIST 8-puzzle         |   193924 | *109096* | x2      |
| MNIST 8-puzzle         |   201156 | *111642* | x2      |
| MNIST 8-puzzle         |   186767 |  *84561* | x2      |
| MNIST 8-puzzle         |   183336 |  *82518* | x2      |
| MNIST 8-puzzle         |   169907 |  *52084* | x3      |
| MNIST 8-puzzle         |   130863 |  *26967* | x5      |
|------------------------+----------+----------+---------|
| Hanoi (4 peg)          |       55 |     *17* | x3      |
|------------------------+----------+----------+---------|
| LightsOut (4x4)        |      952 |     *27* | x30     |
|------------------------+----------+----------+---------|
| Spiral LightsOut (3x3) |      522 |    *214* | x2.5    |
|------------------------+----------+----------+---------|
| Mandrill 8-puzzle      |   335378 |  *88851* | x4      |
|------------------------+----------+----------+---------|
#+end_smaller
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_larger
#+begin_alignright
→ */Leverage the effort from ICAPS community!/*
#+end_alignright
#+end_larger

# #+begin_larger
# PDB: Pattern DataBase ヒューリスティクス
# 
# 注: *プランニングでは理論保証付き下界関数のことをヒューリスティック関数と呼ぶ*
# #+end_larger

* Conclusion

+ Input: Unlabelled pairs of images, initial image, goal image
+ Output: Visualized plans to achieve the goal
+ State AutoEncoder(SAE): VAE with Gumbel-Softmax
+ */Contribution/* : *SAE generates /propositions/ from raw data*

  → *compatible to the symbolic classical planners*
+ Latplan α : *A prototype made /as simple as possible/*

  → Can leverege from the future development of both symbolic/subsymbolic AI research

#+begin_larger
Arxiv 1705.00154 : *Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary.*
#+end_larger

* I expect mixed responses such as...

#+begin_xlarge
+ Wait, what!? you solved the symbol grounding!?
+ Huh, I hate deep learning hype.
+ This is not a planning research.
+ This lacks statistical results.^*
+ This isn't a domain-acquisition.^*
#+end_xlarge

(^* I actually received these responses)

* SAE implementation in LatPlan α

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

　

+ Why full-connected layers ? ::
             Main focus is on *whether propositions made by SAE are feasible*
             
             *→No complication due to CNN, ResNet, etc...*
             
+ Training on 8-puzzle ::
               *12000 images* out of entire states (362880) → *Generalization*

* Domain Acquisition implementation in LatPlan α

_Entire transitions $R$_ → $Encode(R)$ → PDDL

Why? → *Trivial domain acquisition, no generalization*

: Ground      actions 0011 → 0101  (state variables are fully specified)
: Generalized actions *01* → *10*  (state variables are partially specified)

+ LatPlanα: No generalization wrto domain acquisition ::

     Main focus is on *whether propositions made by SAE are /feasible/*
             
     *→No complication due to domain acquisition*
     
     *Developping a generalizer is an entirely different topic*, leave it to existing work

#+begin_note
[Konidaris et.al. 14; Cresswell et al 13]
#+end_note

* Gumbel-Softmax

[[png:sae/gumbel]]

$N\times M$ 行列を出力, $N$: 変数の数 $M$: カテゴリの数

* 他の実行例 (Lights Out)

8-puzzle も hanoi も 「物体」のようなものが「消えない」という性質がある。

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out]]

#+begin_xlarge
#+begin_alignright
 → *同様に最適解を返却*
#+end_alignright
#+end_xlarge

* 他の実行例 (Skewed Lights Out)

8-puzzle, hanoi, LightsOut は 「物体」のようなものが格子状に並んでいる

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out-skewed]]

#+begin_xlarge
#+begin_alignright
 → *同様に最適解を返却*
#+end_alignright
#+end_xlarge

* 正しくない解が出力される可能性はないの？

*ニューラルネットの誤差が大きい場合のみ発生* (収束保証は $t\rightarrow \infty$ のみ, not 実時間)

 → でたらめなシンボル/グラフが生成

 → *でたらめな離散グラフ上の正しいプラン* が生成 / *グラフが非連結* で解なし

#+begin_alignright
 (アルゴリズムの完全性、健全性、最適性により保証)
#+end_alignright

 → でたらめな画像プラン / 解が存在しない

#+begin_center
#+begin_larger
LatPlan に */認識の間違いはある/* が */判断の間違いはない!/*
#+end_larger
#+end_center

#+begin_alignright
 (完全性,最適性) →強化学習に対する強み
#+end_alignright

** 強化学習

*意思決定も学習に依存する*

→ */個別の学習結果に理論保証はない。/*

→ */Policy関数が正しく学習されなかった局面では失敗する。/*

#+begin_quote
セドルはそれから、左手で首の後ろに触れたまま次の手を打った。... 
コンピューターは驚きを隠せなかった。もちろん目をパチクリさせたわけではないが、次の1手はひどいものだった。
[白78手について]
#+end_quote
#+begin_alignright
Cade Metz. "Two Moves, that Redifined the Future." /Wired/, 2016
#+end_alignright

#+begin_center
#+begin_larger
RLは *判断に間違いがあり得る。*
#+end_larger
#+end_center

* Future Work (SAE)

SAEは命題の検出が可能 (状態s = p∧q∧r...)

→ 一階述語への一般化 (述語 p(a,b) )

→ オブジェクトの検出 (引数 a,b) が必要

→ 物体認識(R-CNN) などを内部で用いる より複雑なSAEの使用で対処可能

* Future Work (問題ドメイン)

LatPlan は あくまで *アーキテクチャ*

*SAE の実装を変えれば(原理的には)画像以外の任意の入力データに対応可能なはず*

+ テキスト用のAE [Li et.al. 2015]、 音声用のAE [Deng, Li, et al. 2010]
+ 改造してSAEにすれば・・・
  + *Here's an Apple, Here's a pen → oh, ApplePen!*
+ SAEを学習してプランナで解く → *数千ステップの高速な言語レベル推論が可能に*

#+begin_note
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+end_note


* 記号・記号処理とは

*記号の特徴と強み* : なぜ記号は強力な抽象化の道具なのか？

+ 理解する必要がない ::
     ルールを機械的に適用することだけによって論理推論を行える
     
     シンボル $X$ の意味がリンゴだろうと車だろうと ルールが正しければ推論できる
     
     + ドメイン非依存ソルバの顕著な例: *mystery* ドメインと *nomystery* ドメイン

       *シンボル名だけデタラメ* にした荷物配送ベンチマーク (truck → shark)

       */(名前を見て特殊アルゴリズムを使う不正を禁じるため)/*
  
+ 組み合わせが可能 :: 
     Latent vector は 複数の命題の連言 (and) → modus ponens が適用可能になる
     
     探索の下界関数はこれらを適用してゴールへの近さを見積もる

+ ノイズを含む画像ピクセルはそのままではシンボルになれない ::

     ノイズの有無で画像は全く異なるデータになる → 何か *共通の特徴* の抽出が必要
     
     
* Arxiv版を上げた際のTwitterでの議論

 [[png:twitter]]

#+begin_center
#+begin_xlarge
*/AlphaGo チーム全員:/*

*/「古典プランニング超大事!」/*
#+end_xlarge
#+end_center

* 評価

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ 学習: 30分程度
+ 求解: 3秒程度

** State AutoEncoder

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像 (注!)

[[spng:experiment/autoencoding_test]]

#+begin_alignright
きちんと学習できている
#+end_alignright

** State AutoEncoder

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

$N=25$ の例

#+begin_src lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

** 先ほどの結果

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6

[[png:results/mnist-plan]]

[[png:results/mandrill-plan]]

#+end_span6
#+begin_span6

[[png:results/hanoi3]]

[[png:results/hanoi4]]

[[png:results/lights-out]]

[[png:results/lights-out-skewed]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Fast Downward Log Trace (Search Statistics)                     :noexport:


#+begin_example
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+end_example

