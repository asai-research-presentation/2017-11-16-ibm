#+title: 
#+author: 
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+begin_outline-text-1
#+begin_center

#+begin_larger
_Masataro Asai_, Alex Fukunaga, The University of Tokyo
#+end_larger

#+begin_xlarge
Classical Planning

in Deep Latent Space:

From Unlabelled Images

to PDDL (and back)
#+end_xlarge

#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* The */Killer App/* of AI Planning                                :noexport:


#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_larger
+ Places unreachable to mankind :: Nuclear Plant, Deep Space, Mars, Deep Sea
+ Where completeness, soundness and optimality matters :: 
     Satellite, Manufacturing, Logistics
+ Explainable systems :: 
     Rescue mission, Spaceship
#+end_larger

# [[sjpg:martian]]

#+end_span7
#+begin_span5

[[sjpg:gravity-m]]

#+end_span5
#+end_row-fluid
#+end_container-fluid

* Deep Neural Networks

　

　

[[png:deeplearning/1]]

** Human-competitive results in cognitive tasks

[[png:deeplearning/dl-image-task]]

** Human-competitive results in cognitive tasks

[[png:deeplearning/dl-nlp-task]]

* Deep Learning vs Planning

 Main differences: Purposes and the abstraction layer

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *Machine Learning, Neural Networks* 
 
 for *Recognition, Reflex*
 + *Subsymbolic Input* (continuous)
   
   Images, Audio, unstructured text: 
 + *Soft Intelligence*:
   
   　 */Reflex Agent/, /Immediate/ actions*
   #+BEGIN_SMALLER
   *Pavlov's dog* : food → drool

   *Autonomous Driving* : Pedestrian → Stop.

   *Machine Translation* : Sentence → Sentence

   *Eval. Function for Go* : board → win-rate
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ Efficient 1-to-1 mapping
   
   ☹ Simple tasks
   #+END_LARGER
 #+END_SPAN6
 #+BEGIN_SPAN6
 *Deliberation, Search*

 for *Planning, Game, Theorem Proving*
 + *Symbolic Input/Output*
   
   Logic, objects, induction rules
 + *Hard Intelligence by Logic:*

   　 */Multi-step/ strategies*
   
   #+BEGIN_SMALLER
   *Rescue Robot* : actions → help the surviver

   *Theorem Proving* : theorems → QED

   *Compiler* : x86 instructions
   
   *Game of Go* : stones → Win
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ Ordering constraint + complex tasks
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

+ AlphaGo = Subsymbolic (DLNN eval. function) + Symbolic (MCTS)

* Human-Competitive Systems

 AlphaGo = Subsymbolic (NN eval. func) + Symbolic (MCTS)
 + However, *domain-specific* -- specialized in Go, "Grids" / "Stones" are known
 + *Huge expert trace DB* --- Not applicable when data are scarse (e.g. *space exploration*)
 + */Is supervised learning necessary for human?/*
  
   *True intelligence should search / collect data by itself*

 DQN = Subsymbolic (DLNN) + Reinforcement Learning (DLNN)

Domain-independent Atari Game solver (Invader, Packman…), however:
 + RL Acting: Greedily follow the learned policy → *no deliberation!*
 + You can survive most Atari games *by reflex*
  
 # 実際 *Sokoban など論理思考ゲームでは性能が悪い* ↔ 倉庫番ソルバ

* Combining Symbolic AIs and Subsymbolic AIs

[[png:lecun]]

* Our Goal

#+begin_xlarge
#+begin_center
Deep Learning

＋

Classical Planning
#+end_center
#+end_xlarge

** Advantages

#+begin_xlarge
*/Perception/* based on DLNN
#+end_xlarge

--- Robust systems augmented by the latest DL tech

#+begin_xlarge
*/Decision Making/* based on Classical Planning
#+end_xlarge

--- *Better Theoretical Guarantee than Reinforcement Learning*

#+begin_center
*Completeness* (Finds solution whenever possible), */Solution Optimality/*
#+end_center

--- *Decision Making Independent from Learning*

#+begin_center
*/Unsupervised/* (No data required), *Explainable* (Search by logic)
#+end_center

# 今まではNNとの相性から強化学習が優勢だったが *もうその必要はない*

** 3x3 Sliding Tile Puzzle

#+begin_center
362880 configurations

4x4、5x5 puzzles : infeasible under blind search (memory exhaust)

Optimal solutions can be obtained by admissible heuristics
#+end_center

[[sjpg:puzzle]]

** Goal: Solving Imaged-Based 8-puzzle w/o Plan Example, Prior Knowledge

*DLNN + Classical Planning*

*No Prior Knowledge* : labels/symbols such as "9 tiles", "moving"

*No Plan Examples* : (AlphaGo) eval. function learned from expert plans → *admissible heuristic function*

[[sjpg:puzzle]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example, Prior Knowledge

#+begin_xlarge
*/No Prior Knowledge/*

#+begin_alignright
*＝ /Domain-independent Planning/*
#+end_alignright
#+end_xlarge

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Tower of Hanoi

[[sjpg:hanoi]]
#+end_span6
#+begin_span4
Lights-Out

[[sjpg:lightsout]]
#+end_span4
#+end_row-fluid
#+end_container-fluid
* -

#+begin_xlarge
#+begin_center
System Overview
#+end_center
#+end_xlarge

** Input1: Training Inputs -- Image Pairs

Image pairs showing the before/after states of valid actions

[[png:overview/1]]

** Input1: Training Inputs -- Image Pairs

[[png:overview/2]]

** Input2: Planning Inputs -- Initial Image & Goal Image

Visual depiction of the initial state and a single goal state

[[png:overview/input2]]

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** Goal: Solving */ANY/* Imaged-Based tasks w/o Plan Example nor Prior Knowledge

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />
* Results (MNIST 8-puzzle)

8-puzzle using digits from MNIST database

[[png:results/mnist-plan]]

#+begin_larger
An instance whose the optimal solution length is known
#+begin_xlarge
#+begin_alignright
 → *31 step optimal plan*
#+end_alignright
#+end_xlarge
#+end_larger

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

MNIST 8-puzzle has cleanly separated objects -> This domain does not.

[[png:results/mandrill-intro]]

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

[[png:results/mandrill-plan]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solution*
#+end_alignright
#+end_xlarge

** Tower of Hanoi

Completely different puzzle problem can be solved with no change

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution* (7 steps,15 steps)
#+end_xlarge
#+end_alignright

** Lights Out

Completely different puzzle problem can be solved with no change

[[png:results/lights-out]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Twisted Lights Out

Does not assume grid-like structures

[[png:results/lights-out-skewed]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Handling the Noisy Input

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solutions*
#+end_alignright
#+end_xlarge

* Sure it works, how?

DLNN + Classical Planner

+ 1. Extracting knowledge from unlabelled images

  + *For what, and how?*

+ 2. Neural Output is subsymbolic real-valued activations ↔ Symbolic, discrete values, propositions?

  + *Symbol Grounding*

+ 3. Machine-generated symbols are *not human-comprehensive*

  + *How to interpret these /foreign/ symbols?*

* Latent-Space Planner: */LatPlan/*

We propose LatPlan */architechture/*, and *LatPlanα*, an implementation

 [[png:overview/planning1]]

* Step 1: State Autoencoder

A neural network *bridging the Symbolic/Subsymbolic boundary*

 [[png:overview/planning2]]

** Neural Network 101

　

　

[[png:deeplearning/1]]

** Neural Network 101

Layers of inner products of vectors and matrices

　

[[png:deeplearning/2]]

** Neural Network 101

Layers of inner products of vectors and matrices

→ Update *W* using *error* = derivatives → Back propagation learning

[[png:deeplearning/3]]

** Stochastic Gradient Descent + GPU

[[spng:gradient-descent]]

** Standard Classification / Mapping Tasks

+ Target Function $y^*=f^*(x)$
  
  | Task                 | Input x  | Output y                           |
  |----------------------+----------+------------------------------------|
  | Image classification | Image    | Label (1=car, 2=cat, 3=monkey ...) |
  | Translation          | Sentence | Sentence                           |
  | Go eval. function    | State    | Number                             |

+ Actual output $y=f(x)$

+ Learn to minimize $||y-y^*||$ by Backpropagation / SGD

** AutoEncoder : Unsupervised Learning

+ Target Function: Identity function $x=f^*(x)$
+ Map the input vector $x$ to *latent vector* $z$, then back to $x$
+ Dimensionality reduction (space compression): $X \rightarrow Z \rightarrow X$
+ You can extract the compression/decompression part: $Encode: x \mapsto z, Decode: z \mapsto x$

#+begin_container-fluid
#+begin_row-fluid
#+begin_span3

#+end_span3
#+begin_span6
[[png:static/autoenc]]
#+end_span6
#+begin_span3

#+end_span3
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
→ However, */✘ Latent vector is a real-valued blob, incompatible to classical planning/*
#+end_alignright

** Variational AutoEncoder

An AutoEncoder that *can enforce a certain distribution* on the latent vector over the dataset $X$

#+begin_quote
Example: You have $X=$ { 10k images of apples }. If you train a VAE on $X$, then $Encode(X) \approx N(\mu,\sigma)$. for some \mu,\sigma.
#+end_quote

To train a VAE, you need a *reparametrization trick* because random distributions are non-differentiable.

#+begin_quote
Reparametrization for $N(\mu,\sigma)$: $\mu + \sigma N(0,1)$, $\mu$ and $\sigma$ is differentiable, $N(0,1)$ is not.
#+end_quote

** Gumbel-Softmax Reparametrization (Jang, Gu, ICLR2017)

A Reparametrization trick for enforcing *categorical distribution*.

Categorical distribution: 1-hot vector like <0,0,0,1,0,0> .

Below: Represent an MNIST image with 30 variables of 8 categories.

#+begin_center
 #+BEGIN_HTML
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+END_HTML
#+end_center

#+begin_alignright
#+begin_larger
Key idea: *These categorical variables are /directly/ usable as a source of PDDL/SAS*

*N variables with 2 Categories → N propositional variables (true/false)*
#+end_larger
#+end_alignright

** Step 1: State Autoencoder                                       :noexport:

 [[png:sae/state-ae]]

** Gumbel-Softmax: Gumbel-Max の微分可能な近似                     :noexport:

Gumbel-Max: カテゴリごとの確率 ($x$) から one-hot vector ($z$) をサンプルする手法

+ 例: $x=[0.1, 0.1, 0.8] \rightarrow z = [0, 0, 1] \text{or} [1,0,0] \text{or} [0,1,0]$ (確率にそって)

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ 微分可能でない → BP法が使えない → max を 微分可能なsoftmax で近似

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ 温度 $\tau$ を0に近づけるとGumbelMaxに収束: $z$ もone-hotに収束

  \[
  \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  \]

#+begin_note
Maddison et. al., 2014
#+end_note

** Step 1: State Autoencoder

[[png:train-state-ae]]

SAEを学習させることにより以下の関数を得る:

+ $b = Encode(r)$ : *生データ $r$ を 命題列 $b$ に変換する関数*

+ $\tilde{r} = Decode(b)$ : *命題列 $b$ を 生データ $\tilde{r}$ に変換する関数*

* Step 2: Domain Acquisition (ドメイン獲得)

bitvector から PDDL モデルを生成する

 [[png:overview/planning3]]

** LatPlan の実装 LatPlan α での アクション集合の生成

個別アクション遷移をPDDLアクション表現にマップ

#+begin_src lisp
 0011 → 0101

　　　↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; 遷移前の状態
 :effect       (and (not (b1-false)) (b1-true)    ; false命題を取り除き、true命題を追加
                    (not (b2-true))  (b2-false)))
#+end_src

ポイント:

#+begin_center
 $i$ ビット目が 1 → 命題 ($b_i$-true)

 $i$ ビット目が 0 → 命題 ($b_i$-false)
#+end_center

* Step 3: PDDL モデルを解く

 [[png:overview/planning4]]

* Step 4: 記号的プラン(人には理解不能)を 人の理解できる画像に戻す

 [[png:overview/planning5]]

* わざわざプランニングソルバを使う理由は?

なぜ、ただの幅優先やDijkstra探索ではだめなの?

→ 大規模な問題(5x5パズル等)で *指数爆発* し、非実用的

→ *ドメイン非依存下界関数* (*PDB*) による枝刈り が、この未知のドメインでも有効

#+begin_smaller
|------------------------+----------+----------+--------|
| /                      |        < |        > | <>     |
|                        |          |      <r> |        |
| 探索ノード数           | Dijkstra |   A*+PDB | 高速化 |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   193924 | *109096* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   201156 | *111642* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   186767 |  *84561* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   183336 |  *82518* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   169907 |  *52084* | x3     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   130863 |  *26967* | x5     |
|------------------------+----------+----------+--------|
| Hanoi (4 peg)          |       55 |     *17* | x3     |
|------------------------+----------+----------+--------|
| LightsOut (4x4)        |      952 |     *27* | x30    |
|------------------------+----------+----------+--------|
| Spiral LightsOut (3x3) |      522 |    *214* | x2.5   |
|------------------------+----------+----------+--------|
| Mandrill 8-puzzle      |   335378 |  *88851* | x4     |
|------------------------+----------+----------+--------|
#+end_smaller

#+begin_larger
#+begin_alignright
→ */プランナを使えば既存の様々な下界関数を利用できる!/*
#+end_alignright
#+end_larger

# #+BEGIN_LARGER
# PDB: Pattern DataBase ヒューリスティクス
# 
# 注: *プランニングでは理論保証付き下界関数のことをヒューリスティック関数と呼ぶ*
# #+END_LARGER

* Conclusion

+ 入力: ラベル無しの 状態遷移の画像・初期画像・ゴール画像
+ 出力: ゴールを達成するためのプランを表す画像列
+ State AutoEncoder(SAE): Gumbel-Softmaxを用いたVAE
+ */成果/* : *SAEによって生データから命題を生成 → 古典プランニング問題として解ける* ことを実証
+ */限りなく単純に作った/* プロトタイプ 

  → 記号/非記号AI分野の様々な技術を取り入れることで */より発展/*

JSAI予稿論文は 短縮版です。

#+begin_larger
Arxiv 1705.00154 : *Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary.*

KEPS17採択版: *Classical Planning in Deep Latent Space: From Unlabeled Images to PDDL (and back).*  /Knowledge Engineering for Planning and Scheduling (KEPS) Workshop in ICAPS2017/
#+end_larger


* LatPlan の実装 LatPlan α でのSAE

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

　

+ なぜ全結合?? ::
             論文の主題は *SAEで命題を作る方針がそもそもうまく行くかどうか*
             
             *→余計な要素を省いて限りなくシンプルに*
             
+ 8-パズルでの訓練 ::
               可能な全状態 (362880) 中 *12000 枚* で訓練 → 汎化能力あり

* Gumbel-Softmax

[[png:sae/gumbel]]

$N\times M$ 行列を出力, $N$: 変数の数 $M$: カテゴリの数

* LatPlan の実装 LatPlan α での アクション集合の生成

_全遷移の画像ペア $R$ を生成_ → $Encode(R)$ → PDDL

なぜ? → *本来は汎化されたルールを得られると良い*

: 未汎化の遷移   0011 → 0101  (遷移前の全ビットを指定)
: 汎化された遷移 *01* → *10*  (一部のビットのみを指定)

+ LatPlanα: 一般化を行わない ::

     論文の主題は *SAEで命題を作る方針がそもそもうまく行くかどうか*
     
     *→余計な要素を省いて限りなくシンプルに*
     
     *汎化ルール → 他の Domain Acquisition 学習機^1 をそのまま使えば良い (Future work)*

#+begin_note
[Konidaris et.al. 14; Cresswell et al 13]
#+end_note

* 他の実行例 (Lights Out)

8-puzzle も hanoi も 「物体」のようなものが「消えない」という性質がある。

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out]]

#+begin_xlarge
#+begin_alignright
 → *同様に最適解を返却*
#+end_alignright
#+end_xlarge

* 他の実行例 (Skewed Lights Out)

8-puzzle, hanoi, LightsOut は 「物体」のようなものが格子状に並んでいる

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out-skewed]]

#+begin_xlarge
#+begin_alignright
 → *同様に最適解を返却*
#+end_alignright
#+end_xlarge

* 正しくない解が出力される可能性はないの？

*ニューラルネットの誤差が大きい場合のみ発生* (収束保証は $t\rightarrow \infty$ のみ, not 実時間)

 → でたらめなシンボル/グラフが生成

 → *でたらめな離散グラフ上の正しいプラン* が生成 / *グラフが非連結* で解なし

#+begin_alignright
 (アルゴリズムの完全性、健全性、最適性により保証)
#+end_alignright

 → でたらめな画像プラン / 解が存在しない

#+begin_center
#+begin_larger
LatPlan に */認識の間違いはある/* が */判断の間違いはない!/*
#+end_larger
#+end_center

#+begin_alignright
 (完全性,最適性) →強化学習に対する強み
#+end_alignright

** 強化学習

*意思決定も学習に依存する*

→ */個別の学習結果に理論保証はない。/*

→ */Policy関数が正しく学習されなかった局面では失敗する。/*

#+begin_quote
セドルはそれから、左手で首の後ろに触れたまま次の手を打った。... 
コンピューターは驚きを隠せなかった。もちろん目をパチクリさせたわけではないが、次の1手はひどいものだった。
[白78手について]
#+end_quote
#+begin_alignright
Cade Metz. "Two Moves, that Redifined the Future." /Wired/, 2016
#+end_alignright

#+begin_center
#+begin_larger
RLは *判断に間違いがあり得る。*
#+end_larger
#+end_center

* Future Work (SAE)

SAEは命題の検出が可能 (状態s = p∧q∧r...)

→ 一階述語への一般化 (述語 p(a,b) )

→ オブジェクトの検出 (引数 a,b) が必要

→ 物体認識(R-CNN) などを内部で用いる より複雑なSAEの使用で対処可能

* Future Work (問題ドメイン)

LatPlan は あくまで *アーキテクチャ*

*SAE の実装を変えれば(原理的には)画像以外の任意の入力データに対応可能なはず*

+ テキスト用のAE [Li et.al. 2015]、 音声用のAE [Deng, Li, et al. 2010]
+ 改造してSAEにすれば・・・
  + *Here's an Apple, Here's a pen → oh, ApplePen!*
+ SAEを学習してプランナで解く → *数千ステップの高速な言語レベル推論が可能に*

#+begin_note
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+end_note

* 苦言                                                             :noexport:

日本には記号的AIの研究者が居なさすぎて完全に砂漠状態 (OR除く)

意思決定と推論に重要な *抽象(abstraction)* や *緩和(relaxation)* といった概念

特に、対話技術とかを古典AIの概念と推論を用いずにやっているかぎり、人工無能以上には成り得ない

# JSAI は *技術* でなくて *目的* によってOSを分けるべき
# 
# + *ディープラーニング* OSと *論理* ではなく 

* AIMA 3rd Ed.                                                     :noexport:

1. Introduction
2. Intelligent Agents
3. Solving Problems by Searching
4. Beyond Classical Search
5. Adversarial Search
6. Constraint Satisfaction Problems
7. Logical Agents
8. First-Order Logic
9. Inference in First-Order Logic
10. Classical Planning
11. Planning and Acting in the Real World
12. Knowledge Representation
13. Quantifying Uncertainty
15. Probabilistic Reasoning over Time
16. Making Simple Decisions
17. Making Complex Decisions
18. Learning from Examples
19. Knowledge in Learning
20. Learning Probabilistic Models
21. Reinforcement Learning
22. Natural Language Processing
23. Natural Language for Communication
24. Perception
25. Robotics
26. Philosophical Foundations
27. AI: The Present and Future

* 記号・記号処理とは

*記号の特徴と強み* : なぜ記号は強力な抽象化の道具なのか？

+ 理解する必要がない ::
     ルールを機械的に適用することだけによって論理推論を行える
     
     シンボル $X$ の意味がリンゴだろうと車だろうと ルールが正しければ推論できる
     
     + ドメイン非依存ソルバの顕著な例: *mystery* ドメインと *nomystery* ドメイン

       *シンボル名だけデタラメ* にした荷物配送ベンチマーク (truck → shark)

       */(名前を見て特殊アルゴリズムを使う不正を禁じるため)/*
  
+ 組み合わせが可能 :: 
     Latent vector は 複数の命題の連言 (and) → modus ponens が適用可能になる
     
     探索の下界関数はこれらを適用してゴールへの近さを見積もる

+ ノイズを含む画像ピクセルはそのままではシンボルになれない ::

     ノイズの有無で画像は全く異なるデータになる → 何か *共通の特徴* の抽出が必要
     
     
* Arxiv版を上げた際のTwitterでの議論

 [[png:twitter]]

#+begin_center
#+begin_xlarge
*/AlphaGo チーム全員:/*

*/「古典プランニング超大事!」/*
#+end_xlarge
#+end_center

* 日本のプランニング研究者: */DL研究者よりさらに少ない/*

[[png:planning-researchers]]

* 評価

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ 学習: 30分程度
+ 求解: 3秒程度

** State AutoEncoder

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像 (注!)

[[spng:experiment/autoencoding_test]]

#+begin_alignright
きちんと学習できている
#+end_alignright

** State AutoEncoder

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

$N=25$ の例

#+begin_src lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

** 先ほどの結果

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6

[[png:results/mnist-plan]]

[[png:results/mandrill-plan]]

#+end_span6
#+begin_span6

[[png:results/hanoi3]]

[[png:results/hanoi4]]

[[png:results/lights-out]]

[[png:results/lights-out-skewed]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Fast Downward Log Trace (Search Statistics)                     :noexport:


#+begin_example
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+end_example

